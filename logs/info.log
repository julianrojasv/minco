2021-01-21 18:47:56,136 - root - INFO - ** Kedro project optimus
2021-01-21 18:49:43,313 - root - INFO - ** Kedro project optimus
2021-01-21 18:51:24,731 - root - INFO - ** Kedro project optimus
2021-01-21 18:51:52,176 - root - INFO - ** Kedro project optimus
2021-01-21 18:52:20,241 - root - INFO - ** Kedro project optimus
2021-01-21 18:53:31,952 - root - INFO - ** Kedro project optimus
2021-01-21 18:54:15,009 - root - INFO - ** Kedro project optimus
2021-01-21 18:55:16,412 - root - INFO - ** Kedro project optimus
2021-01-21 18:55:51,035 - root - INFO - ** Kedro project optimus
2021-01-21 18:58:49,997 - root - INFO - ** Kedro project optimus
2021-01-21 19:00:06,034 - root - INFO - ** Kedro project optimus
2021-01-21 19:00:46,252 - root - INFO - ** Kedro project optimus
2021-01-21 19:00:52,321 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 19:00:52,332 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-01-21 19:03:25,726 - root - INFO - ** Kedro project optimus
2021-01-21 19:03:31,868 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 19:04:33,524 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 19:04:33,549 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 19:04:34,138 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 19:04:34,139 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 19:04:34,402 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 19:04:35,824 - kedro.pipeline.node - ERROR - Node `remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]` failed with error: 
ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''
2021-01-21 19:04:35,829 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "remove_outliers,create_features"
2021-01-21 19:07:17,158 - root - INFO - ** Kedro project optimus
2021-01-21 19:07:23,387 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 19:08:25,259 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 19:08:26,263 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 19:08:27,482 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 19:08:27,485 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 19:08:31,107 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 19:10:51,305 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 19:10:53,086 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 19:10:53,097 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 19:11:39,801 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 19:12:42,620 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 19:12:42,928 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 19:12:42,929 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 19:12:42,936 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 19:12:45,901 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 19:13:23,349 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
'r_agua_r3_a330_ait_507'
2021-01-21 19:13:23,755 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-21 19:23:14,833 - root - INFO - ** Kedro project optimus
2021-01-21 19:23:21,334 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 19:24:39,803 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 19:24:41,095 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 19:24:41,533 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 19:24:41,534 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 19:24:41,790 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 19:29:22,113 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 19:29:22,506 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 19:29:22,521 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 19:29:41,859 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 19:31:08,226 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 19:31:08,523 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 19:31:08,524 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 19:31:08,525 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 19:31:08,854 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 19:32:07,047 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
'r_agua_r9_a330_lit_906_pulg'
2021-01-21 19:32:07,687 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-21 19:42:45,113 - root - INFO - ** Kedro project optimus
2021-01-21 19:42:51,843 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 19:44:54,282 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 19:45:22,154 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 19:45:33,413 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 19:45:33,414 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 19:45:33,753 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 19:53:28,659 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 19:53:30,417 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 19:53:30,418 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 19:54:27,397 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 19:56:50,866 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 19:56:51,190 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 19:56:51,191 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 19:56:51,192 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 19:56:51,688 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 19:58:07,234 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
cannot reindex from a duplicate axis
2021-01-21 19:58:07,586 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-21 20:06:42,029 - root - INFO - ** Kedro project optimus
2021-01-21 20:06:49,201 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 20:08:25,326 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 20:08:41,340 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 20:08:41,760 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 20:08:41,761 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 20:08:42,039 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 20:14:08,380 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 20:14:08,776 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 20:14:08,777 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 20:14:19,828 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 20:15:18,833 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 20:15:19,129 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 20:15:19,130 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 20:15:19,280 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 20:15:21,034 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 20:16:35,802 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
cannot reindex from a duplicate axis
2021-01-21 20:16:36,350 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-21 20:28:33,279 - root - INFO - ** Kedro project optimus
2021-01-21 20:28:39,585 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 20:30:00,585 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 20:30:04,399 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 20:30:04,659 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 20:30:04,660 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 20:30:04,916 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 20:34:12,738 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 20:34:13,125 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 20:34:13,128 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 20:34:35,342 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 20:35:47,317 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 20:35:47,598 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 20:35:47,599 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 20:35:47,600 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 20:35:52,934 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 20:37:06,897 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
'sag:dit2189b'
2021-01-21 20:37:07,006 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-21 23:26:17,347 - root - INFO - ** Kedro project optimus
2021-01-21 23:26:24,391 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 23:27:26,898 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 23:27:29,262 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 23:27:29,677 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 23:27:29,678 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 23:27:29,957 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 23:29:27,240 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 23:29:27,727 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 23:29:27,730 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 23:29:36,228 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 23:30:47,863 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 23:30:48,367 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 23:30:48,370 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 23:30:48,371 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 23:30:53,921 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 23:32:08,582 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
'Solido_Convencional'
2021-01-21 23:32:08,656 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-21 23:34:25,481 - root - INFO - ** Kedro project optimus
2021-01-21 23:34:31,715 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 23:35:44,944 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 23:35:46,630 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 23:35:46,892 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 23:35:46,892 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 23:35:47,146 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 23:38:40,172 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 23:38:40,942 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 23:38:40,970 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 23:38:46,645 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 23:39:39,013 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 23:39:39,282 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 23:39:39,283 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 23:39:39,284 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 23:39:39,569 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 23:40:51,128 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
'Solido_Convencional'
2021-01-21 23:40:51,225 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-21 23:45:55,715 - root - INFO - ** Kedro project optimus
2021-01-21 23:46:01,963 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 23:47:18,943 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 23:47:20,661 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 23:47:20,918 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 23:47:20,918 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 23:47:21,179 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 23:48:54,076 - root - INFO - ** Kedro project optimus
2021-01-21 23:49:00,284 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-21 23:50:09,298 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-21 23:50:12,941 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-21 23:50:13,216 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-21 23:50:13,217 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-21 23:50:13,500 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-21 23:52:36,030 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-21 23:52:36,379 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-21 23:52:36,383 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-21 23:52:41,690 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-21 23:53:34,953 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-21 23:53:35,248 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-21 23:53:35,249 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-21 23:53:35,270 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-21 23:53:35,553 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-21 23:54:48,573 - kedro.pipeline.node - ERROR - Node `create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]` failed with error: 
'tph_sag_mills'
2021-01-21 23:54:48,724 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features"
2021-01-22 00:02:27,933 - root - INFO - ** Kedro project optimus
2021-01-22 00:02:34,067 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-22 00:03:33,874 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-22 00:03:36,104 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-22 00:03:36,379 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks
2021-01-22 00:03:36,380 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-22 00:03:36,656 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-22 00:05:37,127 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-22 00:05:37,761 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks
2021-01-22 00:05:37,765 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-22 00:05:53,233 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-22 00:06:51,064 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-22 00:06:51,398 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks
2021-01-22 00:06:51,399 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-01-22 00:06:51,400 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-22 00:06:51,753 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-01-22 00:08:30,290 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-01-22 00:08:30,557 - kedro.runner.sequential_runner - INFO - Completed 4 out of 5 tasks
2021-01-22 00:08:30,558 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-01-22 00:08:35,894 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_esp]
2021-01-22 00:08:42,791 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_esp` (CSVDataSet)...
2021-01-22 00:09:56,067 - kedro.runner.sequential_runner - INFO - Completed 5 out of 5 tasks
2021-01-22 00:09:56,068 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-01-22 15:13:15,454 - root - INFO - ** Kedro project optimus
2021-01-22 15:16:33,750 - root - INFO - ** Kedro project optimus
2021-01-22 15:16:40,289 - kedro.io.data_catalog - INFO - Loading data from `input_data_espesadores_de` (CSVDataSet)...
2021-01-22 15:17:45,240 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([input_data_espesadores_de]) -> [data_norm]
2021-01-22 15:17:59,179 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-01-22 15:18:02,608 - kedro.runner.sequential_runner - INFO - Completed 1 out of 7 tasks
2021-01-22 15:18:02,609 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-01-22 15:18:02,921 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-01-22 15:20:08,805 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-01-22 15:20:09,350 - kedro.runner.sequential_runner - INFO - Completed 2 out of 7 tasks
2021-01-22 15:20:09,362 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-01-22 15:20:30,642 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-01-22 15:22:09,218 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-01-22 15:22:09,523 - kedro.runner.sequential_runner - INFO - Completed 3 out of 7 tasks
2021-01-22 15:22:09,524 - kedro.io.data_catalog - INFO - Loading data from `params:parametros_espesadores` (MemoryDataSet)...
2021-01-22 15:22:09,531 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-01-22 15:22:09,848 - kedro.pipeline.node - INFO - Running node: create_features_esp: create_features_espesadores([data_general,params:parametros_espesadores]) -> [data_features_esp]
2021-01-22 15:23:49,736 - kedro.io.data_catalog - INFO - Saving data to `data_features_esp` (MemoryDataSet)...
2021-01-22 15:23:50,054 - kedro.runner.sequential_runner - INFO - Completed 4 out of 7 tasks
2021-01-22 15:23:50,055 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_aguas` (MemoryDataSet)...
2021-01-22 15:23:50,055 - kedro.io.data_catalog - INFO - Loading data from `data_features_esp` (MemoryDataSet)...
2021-01-22 15:23:56,042 - kedro.pipeline.node - INFO - Running node: create_features_aguas: create_features_aguas([data_features_esp,params:general_tags_aguas]) -> [data_features_agua_esp]
2021-01-22 15:24:02,728 - kedro.io.data_catalog - INFO - Saving data to `data_features_agua_esp` (MemoryDataSet)...
2021-01-22 15:24:03,039 - kedro.runner.sequential_runner - INFO - Completed 5 out of 7 tasks
2021-01-22 15:24:03,040 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_mol` (MemoryDataSet)...
2021-01-22 15:24:03,041 - kedro.io.data_catalog - INFO - Loading data from `data_features_agua_esp` (MemoryDataSet)...
2021-01-22 15:24:03,335 - kedro.pipeline.node - INFO - Running node: create_features_min: create_features_min([data_features_agua_esp,params:general_tags_mol]) -> [data_all_features_general]
2021-01-22 15:24:08,810 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_general` (MemoryDataSet)...
2021-01-22 15:24:09,095 - kedro.runner.sequential_runner - INFO - Completed 6 out of 7 tasks
2021-01-22 15:24:09,096 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_general` (MemoryDataSet)...
2021-01-22 15:24:09,392 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_all_features_general]) -> [data_all_features_esp]
2021-01-22 15:24:16,458 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_esp` (CSVDataSet)...
2021-01-22 15:25:32,885 - kedro.runner.sequential_runner - INFO - Completed 7 out of 7 tasks
2021-01-22 15:25:32,886 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-02-02 17:29:23,201 - root - INFO - ** Kedro project optimus
2021-02-02 17:31:01,787 - root - INFO - ** Kedro project optimus
2021-02-02 17:31:30,237 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 17:31:30,257 - kedro.runner.sequential_runner - WARNING - There are 6 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-02-02 17:40:15,516 - root - INFO - ** Kedro project optimus
2021-02-02 17:40:45,153 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 17:41:48,727 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 17:41:53,279 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 17:41:53,575 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 17:41:53,578 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 17:41:53,965 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 17:44:08,134 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 17:44:09,585 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 17:44:09,589 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 17:45:22,237 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 17:47:34,947 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 17:47:35,335 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 17:47:35,378 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 17:47:35,392 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 17:47:39,432 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 17:48:59,343 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 17:48:59,623 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 17:48:59,624 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 17:48:59,918 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 17:49:00,109 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 
Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'
2021-02-02 17:49:00,169 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-02 18:15:59,026 - root - INFO - ** Kedro project optimus
2021-02-02 18:16:27,257 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 18:17:17,202 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 18:17:19,591 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 18:17:19,957 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 18:17:19,958 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 18:17:20,317 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 18:19:20,159 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 18:19:20,728 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 18:19:20,732 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 18:19:29,464 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 18:20:19,592 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 18:20:19,910 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 18:20:19,910 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 18:20:19,950 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 18:20:24,150 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 18:21:49,320 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 18:21:49,721 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 18:21:49,722 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 18:21:54,907 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 18:21:55,415 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 
Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'
2021-02-02 18:21:55,764 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-02 18:32:20,867 - root - INFO - ** Kedro project optimus
2021-02-02 18:32:48,928 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 18:33:44,093 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 18:33:46,354 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 18:33:46,642 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 18:33:46,643 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 18:33:47,007 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 18:36:08,279 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 18:36:09,162 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 18:36:09,165 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 18:36:16,079 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 18:37:05,414 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 18:37:05,724 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 18:37:05,725 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 18:37:05,739 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 18:37:08,436 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 18:38:32,031 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 18:38:32,318 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 18:38:32,319 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 18:38:32,656 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 18:38:32,670 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-02 18:38:32,874 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-02 18:44:30,357 - root - INFO - ** Kedro project optimus
2021-02-02 18:44:58,405 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 18:45:53,942 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 18:45:56,062 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 18:45:56,376 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 18:45:56,377 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 18:45:56,671 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 18:47:37,558 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 18:47:38,090 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 18:47:38,129 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 18:47:44,515 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 18:48:54,592 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 18:48:55,048 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 18:48:55,049 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 18:48:55,056 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 18:48:55,367 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 18:50:14,259 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 18:50:14,540 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 18:50:14,540 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 18:50:14,811 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 18:50:15,225 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 
Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'
2021-02-02 18:50:15,417 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-02 18:56:09,861 - root - INFO - ** Kedro project optimus
2021-02-02 18:56:38,714 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 18:57:34,250 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 18:57:36,512 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 18:57:36,814 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 18:57:36,815 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 18:57:37,122 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 18:59:05,137 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 18:59:05,589 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 18:59:05,597 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 18:59:12,009 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 18:59:59,380 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 18:59:59,741 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 18:59:59,748 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 18:59:59,812 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 19:00:00,113 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 19:01:45,390 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 19:01:45,672 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 19:01:45,673 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 19:01:50,731 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 19:01:59,360 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 19:01:59,398 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-02 19:01:59,399 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-02 19:01:59,443 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 19:01:59,489 - kedro.pipeline.node - INFO - Running node: add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]
2021-02-02 19:01:59,546 - kedro.pipeline.node - ERROR - Node `add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]` failed with error: 
'on_off_R2'
2021-02-02 19:01:59,893 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-02 19:28:08,049 - root - INFO - ** Kedro project optimus
2021-02-02 19:28:35,962 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 19:29:30,238 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 19:29:32,521 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 19:29:32,809 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 19:29:32,810 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 19:29:33,181 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 19:31:43,413 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 19:31:44,008 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 19:31:44,013 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 19:31:50,948 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 19:32:51,455 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 19:32:51,741 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 19:32:51,742 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 19:32:51,751 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 19:32:52,061 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 19:34:36,786 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 19:34:37,078 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 19:34:37,078 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 19:34:42,514 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 19:34:50,039 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 19:34:50,108 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-02 19:34:50,124 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-02 19:34:50,178 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 19:34:50,229 - kedro.pipeline.node - INFO - Running node: add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]
2021-02-02 19:34:51,356 - kedro.pipeline.node - ERROR - Node `add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]` failed with error: 
"['Fecha'] not in index"
2021-02-02 19:34:51,535 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-02 19:46:29,629 - root - INFO - ** Kedro project optimus
2021-02-02 19:46:57,039 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 19:46:57,047 - kedro.runner.sequential_runner - WARNING - There are 6 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-02-02 20:04:26,097 - root - INFO - ** Kedro project optimus
2021-02-02 20:04:55,257 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 20:05:44,849 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 20:05:47,218 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 20:05:47,547 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 20:05:47,548 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 20:05:47,934 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 20:08:01,998 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 20:08:02,529 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 20:08:02,533 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 20:08:09,388 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 20:08:53,504 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 20:08:53,861 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 20:08:53,862 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 20:08:53,903 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 20:08:54,777 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 20:10:16,572 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 20:10:16,852 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 20:10:16,852 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 20:10:17,135 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 20:10:23,963 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 20:10:24,017 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-02 20:10:24,034 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-02 20:10:24,049 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 20:10:24,098 - kedro.pipeline.node - INFO - Running node: add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]
2021-02-02 20:10:24,799 - kedro.pipeline.node - ERROR - Node `add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]` failed with error: 
"['Fecha'] not in index"
2021-02-02 20:10:24,908 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-02 20:17:10,851 - root - INFO - ** Kedro project optimus
2021-02-02 20:17:38,265 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-02 20:18:32,284 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-02 20:18:34,618 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-02 20:18:34,919 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-02 20:18:34,920 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-02 20:18:35,289 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-02 20:20:24,029 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-02 20:20:24,525 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-02 20:20:24,535 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-02 20:20:31,688 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-02 20:21:15,377 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-02 20:21:15,646 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-02 20:21:15,647 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-02 20:21:15,912 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-02 20:21:16,203 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-02 20:23:03,385 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-02 20:23:03,682 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-02 20:23:03,705 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-02 20:23:10,438 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-02 20:23:17,735 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 20:23:17,788 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-02 20:23:17,788 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-02 20:23:17,811 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_grouped` (MemoryDataSet)...
2021-02-02 20:23:17,887 - kedro.pipeline.node - INFO - Running node: add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]
2021-02-02 20:23:19,078 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_esp` (CSVDataSet)...
2021-02-02 20:24:09,955 - kedro.runner.sequential_runner - INFO - Completed 6 out of 6 tasks
2021-02-02 20:24:09,955 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-02-03 13:33:06,859 - root - INFO - ** Kedro project optimus
2021-02-03 13:33:34,679 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 13:34:29,169 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 13:34:29,170 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 13:34:29,174 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 13:34:29.174581 to None
2021-02-03 13:34:29,175 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 13:34:29,654 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3518, 3179)
2021-02-03 13:34:29,655 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 13:34:45,366 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 13:34:45,367 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 13:35:31,566 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 13:35:31,596 - kedro.pipeline.node - ERROR - Node `parse_columns: norm_columns_name([data_det]) -> [data_clean]` failed with error: 
'Fecha'
2021-02-03 13:35:31,602 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "parse_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],revestimiento_columns,generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 13:46:16,613 - root - INFO - ** Kedro project optimus
2021-02-03 13:46:44,089 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 13:47:44,826 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 13:47:44,848 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 13:47:58,022 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 13:47:58,023 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 13:48:53,200 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 13:48:53,201 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 13:48:53,201 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 13:48:53.201933 to None
2021-02-03 13:48:53,202 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 13:48:53,604 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3517, 3179)
2021-02-03 13:48:53,605 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 13:49:09,244 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 13:49:09,245 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 13:49:12,281 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 13:49:12,291 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 13:49:12,292 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 13:49:12,293 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 13:49:12,295 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 13:49:12,307 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 13:59:51,479 - root - INFO - ** Kedro project optimus
2021-02-03 14:00:18,981 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:01:08,646 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 14:01:08,647 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 14:01:08,647 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 14:01:08.647826 to None
2021-02-03 14:01:08,648 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 14:01:09,106 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3515, 3179)
2021-02-03 14:01:09,106 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 14:01:24,435 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 14:01:24,436 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:02:12,157 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 14:02:12,188 - kedro.pipeline.node - ERROR - Node `parse_columns: norm_columns_name([data_det]) -> [data_clean]` failed with error: 
'Fecha'
2021-02-03 14:02:12,193 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],parse_columns,revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 14:03:37,752 - root - INFO - ** Kedro project optimus
2021-02-03 14:04:05,240 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:04:53,998 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 14:04:53,999 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 14:04:54,000 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 14:04:54.000182 to None
2021-02-03 14:04:54,000 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 14:04:54,401 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3515, 3179)
2021-02-03 14:04:54,402 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 14:05:09,591 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 14:05:09,592 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:05:58,253 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 14:05:58,281 - kedro.pipeline.node - ERROR - Node `parse_columns: norm_columns_name([data_det]) -> [data_clean]` failed with error: 
'fecha'
2021-02-03 14:05:58,288 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],parse_columns,revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 14:08:56,181 - root - INFO - ** Kedro project optimus
2021-02-03 14:09:23,559 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:10:13,219 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 14:10:13,241 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 14:10:22,014 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 14:10:22,015 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:11:15,982 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 14:11:15,983 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 14:11:15,984 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 14:11:15.984170 to None
2021-02-03 14:11:15,985 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 14:11:16,389 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3514, 3179)
2021-02-03 14:11:16,390 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 14:11:31,662 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 14:11:31,663 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 14:11:34,633 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 14:11:34,644 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 14:11:34,645 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 14:11:34,645 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 14:11:34,647 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 14:11:34,660 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 14:12:32,126 - root - INFO - ** Kedro project optimus
2021-02-03 14:12:59,622 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:13:48,357 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 14:13:48,358 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 14:13:48,359 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 14:13:48.359485 to None
2021-02-03 14:13:48,360 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 14:13:48,769 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3514, 3180)
2021-02-03 14:13:48,770 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 14:14:03,914 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 14:14:03,915 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 14:14:51,902 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 14:14:51,926 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 14:14:59,011 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 14:14:59,012 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 14:15:03,435 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 14:15:03,445 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 14:15:03,446 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 14:15:03,446 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 14:31:57,135 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-03 14:32:11,010 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 2481 columns from 3181
2021-02-03 14:36:18,486 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1361 columns from 3182
2021-02-03 14:36:18,566 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
local variable 'ks_test_sum' referenced before assignment
2021-02-03 14:36:18,573 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 14:59:28,031 - root - INFO - ** Kedro project optimus
2021-02-03 15:00:30,710 - root - INFO - ** Kedro project optimus
2021-02-03 15:04:59,646 - root - INFO - ** Kedro project optimus
2021-02-03 15:05:29,864 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 15:08:58,859 - root - INFO - ** Kedro project optimus
2021-02-03 15:09:26,163 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 15:10:28,018 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 15:10:28,041 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 15:10:41,905 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 15:10:41,906 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 15:11:35,945 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 15:11:35,946 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 15:11:35,946 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 15:11:35.946674 to None
2021-02-03 15:11:35,947 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 15:11:36,383 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3508, 3180)
2021-02-03 15:11:36,384 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 15:11:51,439 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 15:11:51,440 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 15:11:54,380 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 15:11:54,391 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na]
2021-02-03 15:11:54,391 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 15:11:54,392 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 15:28:41,593 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-03 15:28:54,909 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 2481 columns from 3181
2021-02-03 15:33:13,260 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1360 columns from 3182
2021-02-03 15:33:13,653 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na]` failed with error: 
local variable 'ks_test_sum' referenced before assignment
2021-02-03 15:33:13,670 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 15:59:42,896 - root - INFO - ** Kedro project optimus
2021-02-03 16:00:11,926 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 16:01:18,577 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 16:01:18,600 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 16:01:30,353 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 16:01:30,355 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 16:02:19,117 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 16:02:19,118 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 16:02:19,119 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 16:02:19.119025 to None
2021-02-03 16:02:19,120 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 16:02:19,575 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3503, 3180)
2021-02-03 16:02:19,576 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 16:02:34,829 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 16:02:34,829 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 16:02:38,152 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 16:02:38,163 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na]
2021-02-03 16:02:38,164 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 16:02:38,165 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 16:18:35,435 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-03 16:18:46,421 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 2481 columns from 3181
2021-02-03 16:22:30,077 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1360 columns from 3182
2021-02-03 16:22:30,114 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na]` failed with error: 
local variable 'ks_test_sum' referenced before assignment
2021-02-03 16:22:30,121 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 16:27:55,988 - root - INFO - ** Kedro project optimus
2021-02-03 16:28:23,945 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 16:29:29,653 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 16:29:29,675 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 16:29:39,578 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 16:29:39,578 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 16:30:26,942 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 16:30:26,943 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 16:30:26,944 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 16:30:26.944013 to None
2021-02-03 16:30:26,944 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 16:30:27,346 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3500, 3180)
2021-02-03 16:30:27,346 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 16:30:42,466 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 16:30:42,467 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 16:30:42,484 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 16:30:47,847 - kedro.io.data_catalog - INFO - Loading data from `revestimiento` (CSVDataSet)...
2021-02-03 16:30:47,863 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 16:38:58,594 - root - INFO - ** Kedro project optimus
2021-02-03 16:39:27,150 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 16:40:26,451 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 16:40:26,475 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 16:40:35,093 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 16:40:35,094 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 16:41:24,518 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 16:41:24,519 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 16:41:24,523 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 16:41:24.523371 to None
2021-02-03 16:41:24,524 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 16:41:24,934 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3499, 3180)
2021-02-03 16:41:24,935 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 16:41:40,781 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 16:41:40,782 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 16:41:43,826 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 16:41:43,836 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na]
2021-02-03 16:41:43,837 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 16:41:43,837 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 16:57:32,890 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-03 16:57:44,323 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-03 17:01:21,002 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1360 columns from 3182
2021-02-03 17:01:21,040 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na]` failed with error: 
local variable 'ks_test_sum' referenced before assignment
2021-02-03 17:01:21,052 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,ks_test_sum,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 17:54:20,785 - root - INFO - ** Kedro project optimus
2021-02-03 17:54:51,940 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 17:56:04,445 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 17:56:04,446 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 17:56:04,451 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 17:56:04.451258 to None
2021-02-03 17:56:04,451 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 17:56:04,871 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3492, 3180)
2021-02-03 17:56:04,872 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 17:56:20,229 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 17:56:20,230 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 17:57:09,663 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 17:57:09,689 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 17:57:29,427 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 17:57:29,428 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 17:57:29,439 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 17:57:36,855 - kedro.io.data_catalog - INFO - Loading data from `revestimiento` (CSVDataSet)...
2021-02-03 17:57:36,867 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]
2021-02-03 17:57:36,869 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]` failed with error: 
Index(['Fecha'], dtype='object')
2021-02-03 17:57:36,875 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 18:09:35,197 - root - INFO - ** Kedro project optimus
2021-02-03 18:10:03,866 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 18:11:13,437 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 18:11:13,460 - kedro.pipeline.node - ERROR - Node `parse_columns: norm_columns_name([data_det]) -> [data_clean]` failed with error: 
'Fecha'
2021-02-03 18:11:13,463 - kedro.runner.sequential_runner - WARNING - There are 6 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-02-03 18:21:04,831 - root - INFO - ** Kedro project optimus
2021-02-03 18:21:32,224 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 18:22:29,793 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 18:22:29,794 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 18:22:29,795 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 18:22:29.795316 to None
2021-02-03 18:22:29,795 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 18:22:30,201 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3489, 3180)
2021-02-03 18:22:30,202 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 18:22:45,008 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 18:22:45,009 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 18:23:33,626 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 18:23:33,648 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 18:23:47,079 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 18:23:47,080 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 18:23:47,092 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 18:23:52,994 - kedro.io.data_catalog - INFO - Loading data from `revestimiento` (CSVDataSet)...
2021-02-03 18:23:53,013 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]
2021-02-03 18:23:53,015 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]` failed with error: 
Index(['Fecha'], dtype='object')
2021-02-03 18:23:53,023 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 18:33:27,050 - root - INFO - ** Kedro project optimus
2021-02-03 18:33:54,701 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 18:35:05,061 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 18:35:05,062 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 18:35:05,063 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 18:35:05.062940 to None
2021-02-03 18:35:05,063 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 18:35:05,481 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3488, 3180)
2021-02-03 18:35:05,481 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 18:35:20,382 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 18:35:20,383 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 18:36:08,410 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 18:36:08,432 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 18:36:22,044 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 18:36:22,045 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 18:36:22,056 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 18:36:27,922 - kedro.io.data_catalog - INFO - Loading data from `revestimiento` (CSVDataSet)...
2021-02-03 18:36:27,941 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]
2021-02-03 18:36:27,943 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 18:36:27,949 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 18:47:12,843 - root - INFO - ** Kedro project optimus
2021-02-03 18:47:40,559 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 18:48:49,897 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 18:48:49,919 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 18:49:01,722 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 18:49:01,723 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 18:49:48,801 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 18:49:48,802 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 18:49:48,802 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 18:49:48.802718 to None
2021-02-03 18:49:48,803 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 18:49:49,203 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3487, 3179)
2021-02-03 18:49:49,204 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 18:50:04,441 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 18:50:04,442 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 18:50:04,452 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 18:50:09,809 - kedro.io.data_catalog - INFO - Loading data from `revestimiento` (CSVDataSet)...
2021-02-03 18:50:09,829 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]
2021-02-03 18:50:09,831 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 18:50:09,837 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 19:11:53,234 - root - INFO - ** Kedro project optimus
2021-02-03 19:12:22,104 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 19:12:22,112 - kedro.runner.sequential_runner - WARNING - There are 6 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-02-03 19:20:24,950 - root - INFO - ** Kedro project optimus
2021-02-03 19:20:53,999 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 19:22:14,391 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 19:22:14,414 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 19:22:26,790 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 19:22:26,791 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 19:23:19,610 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 19:23:19,610 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 19:23:19,611 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 19:23:19.611368 to None
2021-02-03 19:23:19,611 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 19:23:20,036 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3483, 3179)
2021-02-03 19:23:20,037 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 19:23:36,157 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 19:23:36,157 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 19:23:39,708 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 19:23:39,718 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 19:23:39,719 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 19:23:39,719 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 19:23:39,721 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 19:23:39,733 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 19:49:33,859 - root - INFO - ** Kedro project optimus
2021-02-03 19:50:05,643 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 19:50:59,653 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 19:50:59,676 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 19:51:10,359 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 19:51:10,360 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 19:51:10,374 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 19:51:16,923 - kedro.io.data_catalog - INFO - Loading data from `revestimiento` (CSVDataSet)...
2021-02-03 19:51:16,943 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]
2021-02-03 19:51:16,945 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: add_duracion_revestimiento([data_clean,parameters,revestimiento]) -> [data_clean_intermediate]` failed with error: 
Index(['Fecha'], dtype='object')
2021-02-03 19:51:16,953 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,filter_date_range([data_clean_intermediate,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months],apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 19:53:53,515 - root - INFO - ** Kedro project optimus
2021-02-03 19:54:26,574 - root - INFO - ** Kedro project optimus
2021-02-03 19:54:58,769 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 19:56:04,195 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 19:56:04,230 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 19:56:14,219 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 19:56:14,220 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 19:56:14,232 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 19:56:21,346 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-03 19:56:21,349 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]` failed with error: 
Index(['Fecha'], dtype='object')
2021-02-03 19:56:21,359 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,filter_date_range([data_clean_intermediate,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months],apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 20:05:23,382 - root - INFO - ** Kedro project optimus
2021-02-03 20:05:59,694 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:07:18,690 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 20:07:18,716 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 20:07:26,818 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 20:07:26,819 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 20:07:26,832 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 20:07:33,086 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-03 20:07:33,088 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]` failed with error: 
Index(['Fecha'], dtype='object')
2021-02-03 20:07:33,102 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,filter_date_range([data_clean_intermediate,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months],apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 20:08:47,849 - root - INFO - ** Kedro project optimus
2021-02-03 20:09:18,732 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:10:12,106 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 20:10:12,131 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 20:10:19,625 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 20:10:19,626 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 20:10:19,644 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 20:10:26,218 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-03 20:10:26,221 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 20:10:26,229 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,filter_date_range([data_clean_intermediate,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months],apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 20:18:01,380 - root - INFO - ** Kedro project optimus
2021-02-03 20:18:31,353 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:19:24,947 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 20:19:24,948 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 20:19:24,949 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 20:19:24.949145 to None
2021-02-03 20:19:24,949 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 20:19:25,455 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3478, 3179)
2021-02-03 20:19:25,456 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 20:19:41,675 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 20:19:41,675 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:20:35,510 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 20:20:35,544 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 20:20:49,374 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 20:20:49,375 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 20:20:52,514 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 20:20:52,525 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 20:20:52,526 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 20:20:52,527 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 20:20:52,528 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 20:20:52,533 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 20:29:28,123 - root - INFO - ** Kedro project optimus
2021-02-03 20:30:00,288 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:31:00,331 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 20:31:00,354 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 20:31:06,708 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 20:31:06,709 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:32:06,340 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 20:32:06,341 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 20:32:06,342 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 20:32:06.342616 to None
2021-02-03 20:32:06,343 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3179)
2021-02-03 20:32:06,767 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3476, 3179)
2021-02-03 20:32:06,768 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 20:32:23,203 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 20:32:23,204 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 20:32:26,420 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 20:32:26,431 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 20:32:26,432 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 20:34:50,341 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 20:38:09,305 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 

2021-02-03 20:38:09,319 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 20:38:24,149 - root - INFO - ** Kedro project optimus
2021-02-03 20:38:54,293 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:39:56,474 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 20:39:56,498 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 20:40:05,438 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 20:40:05,438 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:41:02,722 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 20:41:02,722 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 20:41:02,723 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 20:41:02.723518 to None
2021-02-03 20:41:02,724 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 20:41:03,163 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3475, 3180)
2021-02-03 20:41:03,164 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 20:41:18,809 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 20:41:18,809 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 20:41:22,078 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 20:41:22,089 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 20:41:22,089 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 20:42:16,838 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 20:44:03,634 - root - INFO - ** Kedro project optimus
2021-02-03 20:44:33,274 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:45:29,595 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 20:45:29,596 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 20:45:29,597 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 20:45:29.597210 to None
2021-02-03 20:45:29,597 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 20:45:30,116 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3475, 3180)
2021-02-03 20:45:30,117 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 20:45:46,595 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 20:45:46,596 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 20:46:38,687 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 20:46:38,710 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 20:46:47,141 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 20:46:47,141 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 20:46:47,152 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 20:47:01,635 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-03 20:47:01,637 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-03 20:47:01,648 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 21:39:59,043 - root - INFO - ** Kedro project optimus
2021-02-03 21:40:31,636 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 21:42:02,531 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 21:42:02,553 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 21:42:22,151 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 21:42:22,151 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 21:43:23,378 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 21:43:23,379 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 21:43:23,380 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 21:43:23.380307 to None
2021-02-03 21:43:23,381 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 21:43:23,919 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3469, 3180)
2021-02-03 21:43:23,920 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 21:43:41,622 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 21:43:41,623 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 21:43:41,634 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-03 21:44:00,240 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-03 22:02:49,790 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-03 22:03:46,282 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-03 22:08:09,239 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1357 columns from 3182
2021-02-03 22:08:10,791 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 

2021-02-03 22:08:10,821 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 23:17:51,563 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]` failed with error: 

2021-02-03 23:17:51,577 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-03 23:18:10,034 - root - INFO - ** Kedro project optimus
2021-02-03 23:18:37,507 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 23:19:51,131 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-03 23:19:51,132 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-03 23:19:51,133 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-06 23:19:51.133180 to None
2021-02-03 23:19:51,133 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-03 23:19:51,540 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3460, 3180)
2021-02-03 23:19:51,541 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 23:20:06,352 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-03 23:20:06,353 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-03 23:20:54,526 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-03 23:20:54,548 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-03 23:21:08,467 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-03 23:21:08,468 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-03 23:21:13,658 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-03 23:21:13,669 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-03 23:21:13,670 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-03 23:21:13,670 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-03 23:39:28,516 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-03 23:39:40,022 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-03 23:43:20,127 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1358 columns from 3182
2021-02-03 23:43:20,162 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
local variable 'ks_test_sum' referenced before assignment
2021-02-03 23:43:20,175 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 00:05:36,606 - root - INFO - ** Kedro project optimus
2021-02-04 00:06:06,036 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 00:07:27,584 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 00:07:27,615 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 10:57:11,903 - root - INFO - ** Kedro project optimus
2021-02-04 10:57:39,511 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 10:58:36,071 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 10:58:36,092 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 10:58:43,042 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 10:58:43,043 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 10:59:38,145 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 10:59:38,146 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 10:59:38,147 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 10:59:38.147288 to None
2021-02-04 10:59:38,147 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 10:59:38,562 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3390, 3180)
2021-02-04 10:59:38,563 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 10:59:53,047 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 10:59:53,048 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 10:59:56,020 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 10:59:56,031 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 10:59:56,031 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 10:59:56,032 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 11:16:45,430 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 11:16:59,992 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 11:21:00,008 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1353 columns from 3182
2021-02-04 11:36:54,311 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 

2021-02-04 11:36:54,327 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 11:39:30,479 - root - INFO - ** Kedro project optimus
2021-02-04 11:39:58,756 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 11:41:05,469 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 11:41:05,492 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 11:41:16,148 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 11:41:16,149 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 11:42:04,341 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 11:42:04,341 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 11:42:04,342 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 11:42:04.342591 to None
2021-02-04 11:42:04,343 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 11:42:04,753 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3385, 3180)
2021-02-04 11:42:04,754 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 11:42:19,536 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 11:42:19,537 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 11:42:19,548 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 11:42:24,799 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 11:42:39,412 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]` failed with error: 

2021-02-04 11:42:39,418 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 11:44:04,014 - root - INFO - ** Kedro project optimus
2021-02-04 11:44:31,591 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 11:45:20,878 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 11:45:20,879 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 11:45:20,880 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 11:45:20.880085 to None
2021-02-04 11:45:20,880 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 11:45:21,286 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3385, 3180)
2021-02-04 11:45:21,287 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 11:45:36,082 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 11:45:36,082 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 11:46:24,965 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 11:46:24,989 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 11:46:32,528 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 11:46:32,529 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 11:46:35,636 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 11:46:35,647 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 11:46:35,647 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 11:46:35,648 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 12:02:48,435 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 12:03:00,198 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 12:06:25,839 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1353 columns from 3182
2021-02-04 12:06:25,878 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
not enough values to unpack (expected 3, got 2)
2021-02-04 12:06:25,890 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],revestimiento_columns,create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 12:14:10,969 - root - INFO - ** Kedro project optimus
2021-02-04 12:14:38,629 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 12:15:51,010 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 12:15:51,033 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 12:16:04,618 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 12:16:04,619 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 12:16:55,681 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 12:16:55,682 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 12:16:55,683 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 12:16:55.683185 to None
2021-02-04 12:16:55,684 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 12:16:56,097 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3382, 3180)
2021-02-04 12:16:56,098 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 12:17:11,198 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 12:17:11,198 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 12:17:11,209 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 12:17:17,284 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 12:17:17,794 - kedro.pipeline.node - ERROR - Node `revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-04 12:17:17,808 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "revestimiento_columns,apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 12:19:41,167 - root - INFO - ** Kedro project optimus
2021-02-04 12:20:08,995 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 12:21:04,804 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 12:21:04,833 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 12:21:12,398 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 12:21:12,399 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 12:22:04,892 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 12:22:04,892 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 12:22:04,897 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 12:22:04.897581 to None
2021-02-04 12:22:04,898 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 12:22:05,309 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3381, 3180)
2021-02-04 12:22:05,310 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 12:22:20,685 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 12:22:20,686 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 12:22:20,700 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 12:22:26,190 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 12:22:30,130 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 12:22:30,507 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 12:22:30,508 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 12:22:34,886 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 12:22:34,900 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 12:22:34,901 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 12:22:34,902 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 12:38:46,283 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 12:38:59,218 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 12:42:36,920 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1352 columns from 3182
2021-02-04 12:42:36,961 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
not enough values to unpack (expected 3, got 2)
2021-02-04 12:42:36,975 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 12:48:51,240 - root - INFO - ** Kedro project optimus
2021-02-04 12:49:23,765 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 12:50:41,171 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 12:50:41,199 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 12:50:53,955 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 12:50:53,956 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 12:51:45,279 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 12:51:45,280 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 12:51:45,281 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 12:51:45.281357 to None
2021-02-04 12:51:45,282 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 12:51:45,707 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3378, 3180)
2021-02-04 12:51:45,708 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 12:52:01,783 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 12:52:01,784 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 12:52:01,798 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 12:52:07,085 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 12:52:19,989 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 12:52:20,312 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 12:52:20,313 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 12:52:23,398 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 12:52:23,408 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 12:52:23,409 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 12:52:23,409 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 13:08:35,227 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 13:08:47,318 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 13:12:18,250 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1352 columns from 3182
2021-02-04 13:12:18,299 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
name 'ks_test_sum' is not defined
2021-02-04 13:12:18,311 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 13:19:07,861 - root - INFO - ** Kedro project optimus
2021-02-04 13:19:41,747 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 13:20:50,579 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 13:20:50,580 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 13:20:50,581 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 13:20:50.581416 to None
2021-02-04 13:20:50,582 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 13:20:51,007 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3375, 3180)
2021-02-04 13:20:51,007 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 13:21:06,042 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 13:21:06,043 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 13:21:57,348 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 13:21:57,372 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 13:22:11,677 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 13:22:11,678 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 13:22:11,690 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 13:22:17,896 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 13:22:24,596 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 13:22:24,906 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 13:22:24,907 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 13:22:28,382 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 13:22:28,397 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 13:22:28,398 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 13:22:28,399 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 13:38:24,474 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 13:38:38,050 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 13:42:16,849 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1352 columns from 3182
2021-02-04 13:42:16,891 - kedro.pipeline.node - ERROR - Node `apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]` failed with error: 
not enough values to unpack (expected 5, got 4)
2021-02-04 13:42:16,903 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na],create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table],generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 13:46:10,846 - root - INFO - ** Kedro project optimus
2021-02-04 13:46:38,421 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 13:47:48,782 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 13:47:48,805 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 13:48:01,405 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 13:48:01,406 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 13:48:52,437 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 13:48:52,438 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 13:48:52,438 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 13:48:52.438830 to None
2021-02-04 13:48:52,439 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 13:48:52,851 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3373, 3180)
2021-02-04 13:48:52,851 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 13:49:07,563 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 13:49:07,565 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 13:49:07,581 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 13:49:23,218 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 13:49:32,172 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 13:49:32,499 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 13:49:32,500 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 13:49:35,725 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 13:49:35,735 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 13:49:35,736 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 13:49:35,736 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 14:04:56,525 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 14:05:08,364 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 14:09:05,296 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1352 columns from 3182
2021-02-04 14:09:05,429 - kedro.io.data_catalog - INFO - Saving data to `stat_na` (CSVDataSet)...
2021-02-04 14:09:05,577 - kedro.io.data_catalog - INFO - Saving data to `concentrated_data` (CSVDataSet)...
2021-02-04 14:09:05,659 - kedro.io.data_catalog - INFO - Saving data to `null_data` (CSVDataSet)...
2021-02-04 14:09:05,732 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-04 14:09:05,732 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:09:09,478 - kedro.io.data_catalog - INFO - Loading data from `stat_na` (CSVDataSet)...
2021-02-04 14:09:09,494 - kedro.io.data_catalog - INFO - Loading data from `concentrated_data` (CSVDataSet)...
2021-02-04 14:09:09,509 - kedro.io.data_catalog - INFO - Loading data from `null_data` (CSVDataSet)...
2021-02-04 14:09:09,567 - kedro.io.data_catalog - INFO - Loading data from `ks_test_sum` (CSVDataSet)...
2021-02-04 14:09:09,623 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 14:09:09,654 - kedro.pipeline.node - INFO - Running node: create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table]
2021-02-04 14:09:10,058 - kedro.io.data_catalog - INFO - Saving data to `data_qa_table` (ExcelDataSet)...
2021-02-04 14:09:11,125 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-04 14:09:11,126 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 14:09:11,151 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 14:09:11,355 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:09:14,708 - kedro.pipeline.node - INFO - Running node: generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None
2021-02-04 14:09:14,874 - kedro.pipeline.node - ERROR - Node `generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None` failed with error: 
<class 'numpy.ndarray'>
2021-02-04 14:09:14,880 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 14:14:40,664 - root - INFO - ** Kedro project optimus
2021-02-04 14:15:09,001 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 14:16:15,321 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 14:16:15,343 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 14:16:28,256 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 14:16:28,256 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 14:17:20,115 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 14:17:20,392 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 14:17:20,393 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 14:17:20.393497 to None
2021-02-04 14:17:20,394 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 14:17:20,785 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3370, 3180)
2021-02-04 14:17:20,786 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:17:35,162 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 14:17:35,163 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:17:37,967 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 14:17:37,977 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 14:17:37,978 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 14:17:37,978 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 14:35:24,241 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 14:35:36,276 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 14:38:59,221 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1351 columns from 3182
2021-02-04 14:38:59,260 - kedro.io.data_catalog - INFO - Saving data to `stat_na` (CSVDataSet)...
2021-02-04 14:38:59,605 - kedro.io.data_catalog - INFO - Saving data to `concentrated_data` (CSVDataSet)...
2021-02-04 14:38:59,680 - kedro.io.data_catalog - INFO - Saving data to `null_data` (CSVDataSet)...
2021-02-04 14:38:59,737 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 14:38:59,738 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 14:38:59,749 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 14:39:16,611 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 14:39:28,109 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 14:39:28,387 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-04 14:39:28,388 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:39:31,736 - kedro.io.data_catalog - INFO - Loading data from `stat_na` (CSVDataSet)...
2021-02-04 14:39:31,753 - kedro.io.data_catalog - INFO - Loading data from `concentrated_data` (CSVDataSet)...
2021-02-04 14:39:31,769 - kedro.io.data_catalog - INFO - Loading data from `null_data` (CSVDataSet)...
2021-02-04 14:39:31,781 - kedro.io.data_catalog - INFO - Loading data from `ks_test_sum` (CSVDataSet)...
2021-02-04 14:39:31,799 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 14:39:31,817 - kedro.pipeline.node - INFO - Running node: create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table]
2021-02-04 14:39:32,046 - kedro.io.data_catalog - INFO - Saving data to `data_qa_table` (ExcelDataSet)...
2021-02-04 14:39:32,644 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-04 14:39:32,645 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 14:39:32,663 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 14:39:32,759 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:39:35,609 - kedro.pipeline.node - INFO - Running node: generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None
2021-02-04 14:41:32,967 - kedro.pipeline.node - ERROR - Node `generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None` failed with error: 

2021-02-04 14:41:32,971 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 14:41:51,600 - root - INFO - ** Kedro project optimus
2021-02-04 14:42:20,223 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 14:43:27,441 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 14:43:27,466 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 14:43:34,960 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 14:43:34,961 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 14:44:33,727 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 14:44:33,728 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 14:44:33,729 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 14:44:33.729061 to None
2021-02-04 14:44:33,729 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 14:44:34,131 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3367, 3180)
2021-02-04 14:44:34,132 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:44:49,312 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 14:44:49,313 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 14:44:52,320 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 14:44:52,330 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 14:44:52,331 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 14:44:52,332 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 15:01:16,245 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 15:01:30,058 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 15:05:04,622 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1352 columns from 3182
2021-02-04 15:05:04,665 - kedro.io.data_catalog - INFO - Saving data to `stat_na` (CSVDataSet)...
2021-02-04 15:05:04,915 - kedro.io.data_catalog - INFO - Saving data to `concentrated_data` (CSVDataSet)...
2021-02-04 15:05:04,961 - kedro.io.data_catalog - INFO - Saving data to `null_data` (CSVDataSet)...
2021-02-04 15:05:05,003 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 15:05:05,004 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 15:05:05,016 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 15:05:22,568 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 15:05:31,549 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 15:05:31,886 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-04 15:05:31,887 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 15:05:35,579 - kedro.io.data_catalog - INFO - Loading data from `stat_na` (CSVDataSet)...
2021-02-04 15:05:35,604 - kedro.io.data_catalog - INFO - Loading data from `concentrated_data` (CSVDataSet)...
2021-02-04 15:05:35,666 - kedro.io.data_catalog - INFO - Loading data from `null_data` (CSVDataSet)...
2021-02-04 15:05:35,681 - kedro.io.data_catalog - INFO - Loading data from `ks_test_sum` (CSVDataSet)...
2021-02-04 15:05:35,697 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 15:05:35,716 - kedro.pipeline.node - INFO - Running node: create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table]
2021-02-04 15:05:35,994 - kedro.io.data_catalog - INFO - Saving data to `data_qa_table` (ExcelDataSet)...
2021-02-04 15:05:36,951 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-04 15:05:36,952 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 15:05:36,970 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 15:05:37,110 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 15:05:40,216 - kedro.pipeline.node - INFO - Running node: generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None
2021-02-04 15:26:44,147 - kedro.pipeline.node - ERROR - Node `generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None` failed with error: 

2021-02-04 15:26:44,158 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 15:27:50,428 - root - INFO - ** Kedro project optimus
2021-02-04 15:28:23,794 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 15:29:26,679 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 15:29:26,680 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 15:29:26,685 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 15:29:26.685018 to None
2021-02-04 15:29:26,685 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 15:29:27,128 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3363, 3180)
2021-02-04 15:29:27,129 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 15:29:43,539 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 15:29:43,540 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 15:30:39,080 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 15:30:39,105 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 15:30:46,974 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 15:30:46,975 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 15:30:51,621 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 15:30:51,633 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 15:30:51,634 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 15:30:51,635 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 15:47:21,979 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 15:47:35,598 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 15:51:08,266 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1352 columns from 3182
2021-02-04 15:51:08,309 - kedro.io.data_catalog - INFO - Saving data to `stat_na` (CSVDataSet)...
2021-02-04 15:51:08,477 - kedro.io.data_catalog - INFO - Saving data to `concentrated_data` (CSVDataSet)...
2021-02-04 15:51:08,538 - kedro.io.data_catalog - INFO - Saving data to `null_data` (CSVDataSet)...
2021-02-04 15:51:08,608 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 15:51:08,608 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 15:51:08,620 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 15:51:19,072 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 15:51:40,721 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 15:51:41,094 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-04 15:51:41,095 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 15:51:45,137 - kedro.io.data_catalog - INFO - Loading data from `stat_na` (CSVDataSet)...
2021-02-04 15:51:45,154 - kedro.io.data_catalog - INFO - Loading data from `concentrated_data` (CSVDataSet)...
2021-02-04 15:51:45,173 - kedro.io.data_catalog - INFO - Loading data from `null_data` (CSVDataSet)...
2021-02-04 15:51:45,189 - kedro.io.data_catalog - INFO - Loading data from `ks_test_sum` (CSVDataSet)...
2021-02-04 15:51:45,211 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 15:51:45,230 - kedro.pipeline.node - INFO - Running node: create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table]
2021-02-04 15:51:45,508 - kedro.io.data_catalog - INFO - Saving data to `data_qa_table` (ExcelDataSet)...
2021-02-04 15:51:46,186 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-04 15:51:46,187 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 15:51:46,208 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 15:51:46,345 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 15:51:49,418 - kedro.pipeline.node - INFO - Running node: generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None
2021-02-04 16:04:54,327 - kedro.pipeline.node - ERROR - Node `generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None` failed with error: 

2021-02-04 16:04:54,377 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 16:06:15,937 - root - INFO - ** Kedro project optimus
2021-02-04 16:06:45,033 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 16:07:42,418 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 16:07:42,440 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 16:07:51,303 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 16:07:51,304 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 16:08:46,515 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 16:08:46,515 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 16:08:46,516 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 16:08:46.516375 to None
2021-02-04 16:08:46,517 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 16:08:46,928 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3359, 3180)
2021-02-04 16:08:46,929 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 16:09:01,465 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 16:09:01,466 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 16:09:04,311 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 16:09:04,322 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 16:09:04,322 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 16:09:04,323 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 16:27:05,796 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 16:27:19,881 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 16:31:16,790 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1353 columns from 3182
2021-02-04 16:31:17,421 - kedro.io.data_catalog - INFO - Saving data to `stat_na` (CSVDataSet)...
2021-02-04 16:31:17,594 - kedro.io.data_catalog - INFO - Saving data to `concentrated_data` (CSVDataSet)...
2021-02-04 16:31:17,686 - kedro.io.data_catalog - INFO - Saving data to `null_data` (CSVDataSet)...
2021-02-04 16:31:17,727 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 16:31:17,727 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 16:31:17,739 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 16:31:45,423 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 16:32:06,176 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 16:32:06,454 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-04 16:32:06,455 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 16:32:10,204 - kedro.io.data_catalog - INFO - Loading data from `stat_na` (CSVDataSet)...
2021-02-04 16:32:10,219 - kedro.io.data_catalog - INFO - Loading data from `concentrated_data` (CSVDataSet)...
2021-02-04 16:32:10,238 - kedro.io.data_catalog - INFO - Loading data from `null_data` (CSVDataSet)...
2021-02-04 16:32:10,253 - kedro.io.data_catalog - INFO - Loading data from `ks_test_sum` (CSVDataSet)...
2021-02-04 16:32:10,272 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 16:32:10,290 - kedro.pipeline.node - INFO - Running node: create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table]
2021-02-04 16:32:10,516 - kedro.io.data_catalog - INFO - Saving data to `data_qa_table` (ExcelDataSet)...
2021-02-04 16:32:11,084 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-04 16:32:11,084 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 16:32:11,101 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 16:32:11,201 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 16:32:14,147 - kedro.pipeline.node - INFO - Running node: generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None
2021-02-04 16:32:14,248 - kedro.pipeline.node - ERROR - Node `generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None` failed with error: 
<class 'numpy.ndarray'>
2021-02-04 16:32:14,260 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 16:42:11,797 - root - INFO - ** Kedro project optimus
2021-02-04 16:42:39,609 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 16:43:41,518 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 16:43:41,519 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 16:43:41,519 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 16:43:41.519855 to None
2021-02-04 16:43:41,520 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 16:43:41,922 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3355, 3180)
2021-02-04 16:43:41,923 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 16:43:56,276 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 16:43:56,277 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 16:44:44,518 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 16:44:44,542 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 16:44:52,491 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 16:44:52,492 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 16:44:56,948 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 16:44:56,962 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 16:44:56,963 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 16:44:56,963 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 17:03:02,123 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 17:03:13,952 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 17:06:45,320 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1353 columns from 3182
2021-02-04 17:06:45,356 - kedro.io.data_catalog - INFO - Saving data to `stat_na` (CSVDataSet)...
2021-02-04 17:06:45,436 - kedro.io.data_catalog - INFO - Saving data to `concentrated_data` (CSVDataSet)...
2021-02-04 17:06:45,901 - kedro.io.data_catalog - INFO - Saving data to `null_data` (CSVDataSet)...
2021-02-04 17:06:45,956 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 17:06:45,957 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 17:06:45,969 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 17:07:02,481 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 17:07:11,267 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 17:07:12,140 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-04 17:07:12,141 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 17:07:17,734 - kedro.io.data_catalog - INFO - Loading data from `stat_na` (CSVDataSet)...
2021-02-04 17:07:17,750 - kedro.io.data_catalog - INFO - Loading data from `concentrated_data` (CSVDataSet)...
2021-02-04 17:07:17,765 - kedro.io.data_catalog - INFO - Loading data from `null_data` (CSVDataSet)...
2021-02-04 17:07:17,777 - kedro.io.data_catalog - INFO - Loading data from `ks_test_sum` (CSVDataSet)...
2021-02-04 17:07:17,794 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:07:17,811 - kedro.pipeline.node - INFO - Running node: create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table]
2021-02-04 17:07:18,149 - kedro.io.data_catalog - INFO - Saving data to `data_qa_table` (ExcelDataSet)...
2021-02-04 17:07:18,692 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-04 17:07:18,693 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:07:18,719 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 17:07:18,816 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 17:07:21,839 - kedro.pipeline.node - INFO - Running node: generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None
2021-02-04 17:09:46,356 - kedro.pipeline.node - ERROR - Node `generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None` failed with error: 
<class 'numpy.ndarray'>
2021-02-04 17:09:58,518 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None"
2021-02-04 17:12:17,256 - root - INFO - ** Kedro project optimus
2021-02-04 17:12:45,600 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 17:13:49,230 - kedro.pipeline.node - INFO - Running node: parse_columns: norm_columns_name([data_det]) -> [data_clean]
2021-02-04 17:13:49,251 - kedro.io.data_catalog - INFO - Saving data to `data_clean` (PickleDataSet)...
2021-02-04 17:13:59,725 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 17:13:59,726 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 17:14:53,729 - kedro.io.data_catalog - INFO - Loading data from `params:filter_params.data_clean_intermediate_01` (MemoryDataSet)...
2021-02-04 17:14:53,730 - kedro.pipeline.node - INFO - Running node: filter_date_range([data_det,params:filter_params.data_clean_intermediate_01]) -> [data_clean_intermediate_filtered_lasts_months]
2021-02-04 17:14:53,730 - project_clisham.optimus_core.utils - INFO - Filtering the range from 2020-09-07 17:14:53.730806 to None
2021-02-04 17:14:53,731 - project_clisham.optimus_core.utils - INFO - Dataframe shape pre-filter: (57030, 3180)
2021-02-04 17:14:54,139 - project_clisham.optimus_core.utils - INFO - Dataframe shape after filter: (3352, 3180)
2021-02-04 17:14:54,139 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 17:15:08,430 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-04 17:15:08,431 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 17:15:08,442 - kedro.io.data_catalog - INFO - Loading data from `data_clean` (PickleDataSet)...
2021-02-04 17:15:25,796 - kedro.pipeline.node - INFO - Running node: revestimiento_columns: replace_duracion_revestimiento([data_clean,parameters]) -> [data_clean_intermediate]
2021-02-04 17:15:29,543 - kedro.io.data_catalog - INFO - Saving data to `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 17:15:29,851 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-04 17:15:29,852 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 17:15:33,091 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 17:15:33,102 - kedro.pipeline.node - INFO - Running node: apply_cleaning_filters([data_clean_intermediate_filtered_lasts_months,parameters]) -> [concentrated_data,null_data,stat_na]
2021-02-04 17:15:33,103 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Initializing data quality assessment for all sources
2021-02-04 17:15:33,103 - project_clisham.pipelines.data_quality.qa_nodes - INFO - Applying filters to `raw_master_table` source
2021-02-04 17:31:58,107 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _count_monthly_na kept 3179 columns from 3179
2021-02-04 17:32:09,535 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _max_window_na kept 3181 columns from 3181
2021-02-04 17:35:41,177 - project_clisham.pipelines.data_quality.qa_nodes - INFO - _concentrated_data kept 1353 columns from 3182
2021-02-04 17:35:41,212 - kedro.io.data_catalog - INFO - Saving data to `stat_na` (CSVDataSet)...
2021-02-04 17:35:41,570 - kedro.io.data_catalog - INFO - Saving data to `concentrated_data` (CSVDataSet)...
2021-02-04 17:35:41,683 - kedro.io.data_catalog - INFO - Saving data to `null_data` (CSVDataSet)...
2021-02-04 17:35:41,722 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-04 17:35:41,723 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 17:35:44,600 - kedro.io.data_catalog - INFO - Loading data from `stat_na` (CSVDataSet)...
2021-02-04 17:35:44,615 - kedro.io.data_catalog - INFO - Loading data from `concentrated_data` (CSVDataSet)...
2021-02-04 17:35:44,632 - kedro.io.data_catalog - INFO - Loading data from `null_data` (CSVDataSet)...
2021-02-04 17:35:44,645 - kedro.io.data_catalog - INFO - Loading data from `ks_test_sum` (CSVDataSet)...
2021-02-04 17:35:44,668 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:35:44,686 - kedro.pipeline.node - INFO - Running node: create_qa_table([concentrated_data,data_clean_intermediate_filtered_lasts_months,ks_test_sum,null_data,stat_na,tag_dict_master]) -> [data_qa_table]
2021-02-04 17:35:44,921 - kedro.io.data_catalog - INFO - Saving data to `data_qa_table` (ExcelDataSet)...
2021-02-04 17:35:45,757 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-04 17:35:45,757 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:35:45,774 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 17:35:45,872 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate_filtered_lasts_months` (CSVDataSet)...
2021-02-04 17:35:48,773 - kedro.pipeline.node - INFO - Running node: generate_qa_plots([data_clean_intermediate_filtered_lasts_months,data_qa_table,tag_dict_master]) -> None
2021-02-04 17:35:49,077 - kedro.runner.sequential_runner - INFO - Completed 6 out of 6 tasks
2021-02-04 17:35:49,078 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-02-04 17:35:49,079 - kedro.io.data_catalog - INFO - Loading data from `data_clean_intermediate` (MemoryDataSet)...
2021-02-04 17:47:15,303 - root - INFO - ** Kedro project optimus
2021-02-04 17:47:57,849 - root - INFO - ** Kedro project optimus
2021-02-04 17:48:25,772 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 17:48:25,867 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:48:25,883 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 17:48:25,884 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 17:48:25,911 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 17:48:25,932 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 17:48:25,950 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 17:48:25,962 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 17:48:25,976 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 17:48:25,988 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 17:48:26,001 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 17:48:26,018 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 17:48:26,019 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 17:48:26,020 - kedro.runner.sequential_runner - INFO - Completed 1 out of 9 tasks
2021-02-04 17:48:26,020 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 17:49:30,231 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 17:49:30,246 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 17:49:30,247 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_value([data_det,go_or_nogo,parameters]) -> [data_corrected_by_val,data_curation_stats]
2021-02-04 17:49:30,973 - kedro.pipeline.node - ERROR - Node `replace_outliers_by_value([data_det,go_or_nogo,parameters]) -> [data_corrected_by_val,data_curation_stats]` failed with error: 
name 'sag2_320_li_3270' is not defined
2021-02-04 17:49:30,979 - kedro.runner.sequential_runner - WARNING - There are 8 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features,replace_outliers_by_value([data_det,go_or_nogo,parameters]) -> [data_corrected_by_val,data_curation_stats],add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],replace_outliers_by_nan([data_corrected_by_val,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan]"
2021-02-04 17:52:51,701 - root - INFO - ** Kedro project optimus
2021-02-04 17:53:20,141 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 17:53:20,245 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:53:20,261 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 17:53:20,262 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 17:53:20,290 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 17:53:20,305 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 17:53:20,322 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 17:53:20,334 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 17:53:20,347 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 17:53:20,359 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 17:53:20,371 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 17:53:20,386 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 17:53:20,387 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 17:53:20,389 - kedro.runner.sequential_runner - INFO - Completed 1 out of 19 tasks
2021-02-04 17:53:20,389 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:53:20,406 - kedro.pipeline.node - INFO - Running node: create_tag_dict([tag_dict_master]) -> [td]
2021-02-04 17:53:20,466 - kedro.io.data_catalog - INFO - Saving data to `td` (PickleDataSet)...
2021-02-04 17:53:20,541 - kedro.runner.sequential_runner - INFO - Completed 2 out of 19 tasks
2021-02-04 17:53:20,542 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 17:54:12,436 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 17:54:12,446 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 17:54:12,447 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_value([data_det,go_or_nogo,parameters]) -> [data_corrected_by_val,data_curation_stats]
2021-02-04 17:54:13,181 - kedro.pipeline.node - ERROR - Node `replace_outliers_by_value([data_det,go_or_nogo,parameters]) -> [data_corrected_by_val,data_curation_stats]` failed with error: 
name 'sag2_320_li_3270' is not defined
2021-02-04 17:54:13,191 - kedro.runner.sequential_runner - WARNING - There are 17 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],replace_outliers_by_value([data_det,go_or_nogo,parameters]) -> [data_corrected_by_val,data_curation_stats],create_features,replace_outliers_by_nan([data_corrected_by_val,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan],create_time_grid,merge_to_grid,add_sag_features_by_hour([data_primary,parameters]) -> [data_sag_features_by_hour],add_across_features_by_hour([data_sag_features_by_hour,parameters]) -> [data_general_features],group_by_shift([data_general_features,parameters]) -> [data_aggregated],add_sag_features_by_shift([data_aggregated,parameters]) -> [data_sag_features_by_shift],add_across_features_by_shift([data_sag_features_by_shift,parameters]) -> [data_features_by_shift],create_target_counts([data_features_by_shift,data_sag_features_by_hour,parameters,td]) -> [data_aggregated_counts],create_target_lags([data_aggregated_counts,parameters,td]) -> [data_all_features,data_all_features_csv]"
2021-02-04 17:56:56,201 - root - INFO - ** Kedro project optimus
2021-02-04 17:57:25,761 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:57:25,779 - kedro.pipeline.node - INFO - Running node: create_tag_dict([tag_dict_master]) -> [td]
2021-02-04 17:57:25,788 - kedro.io.data_catalog - INFO - Saving data to `td` (PickleDataSet)...
2021-02-04 17:57:25,832 - kedro.runner.sequential_runner - INFO - Completed 1 out of 18 tasks
2021-02-04 17:57:25,833 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 17:57:25,927 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:57:25,943 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 17:57:25,944 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 17:57:25,970 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 17:57:25,985 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 17:57:25,997 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 17:57:26,009 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 17:57:26,021 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 17:57:26,033 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 17:57:26,045 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 17:57:26,057 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 17:57:26,058 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 17:57:26,059 - kedro.runner.sequential_runner - INFO - Completed 2 out of 18 tasks
2021-02-04 17:57:26,060 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 17:58:16,019 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 17:58:16,030 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 17:58:16,047 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 17:58:16,048 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan]
2021-02-04 17:58:24,447 - kedro.io.data_catalog - INFO - Saving data to `data_corrected` (PickleDataSet)...
2021-02-04 17:58:39,170 - kedro.io.data_catalog - INFO - Saving data to `data_curation_stats_nan` (CSVDataSet)...
2021-02-04 17:58:39,198 - kedro.runner.sequential_runner - INFO - Completed 3 out of 18 tasks
2021-02-04 17:58:39,198 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 17:58:39,199 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 17:58:46,609 - kedro.pipeline.node - INFO - Running node: create_time_grid: create_time_grid([data_corrected,params:create_primary]) -> [time_grid]
2021-02-04 17:58:46,705 - kedro.io.data_catalog - INFO - Saving data to `time_grid` (MemoryDataSet)...
2021-02-04 17:58:46,712 - kedro.runner.sequential_runner - INFO - Completed 4 out of 18 tasks
2021-02-04 17:58:46,713 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 17:58:51,694 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected]) -> [data_norm]
2021-02-04 17:58:53,370 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 17:58:53,665 - kedro.runner.sequential_runner - INFO - Completed 5 out of 18 tasks
2021-02-04 17:58:53,666 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-04 17:58:53,924 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-04 18:01:31,150 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-04 18:01:31,983 - kedro.runner.sequential_runner - INFO - Completed 6 out of 18 tasks
2021-02-04 18:01:31,987 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 18:01:31,994 - kedro.io.data_catalog - INFO - Loading data from `time_grid` (MemoryDataSet)...
2021-02-04 18:01:32,004 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:02:36,608 - kedro.pipeline.node - INFO - Running node: merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]
2021-02-04 18:05:02,738 - kedro.pipeline.node - ERROR - Node `merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]` failed with error: 
Merging dataframe 1 led to a change in the number of rows from 9500 to 9503. Please check for duplicate timestamps.
2021-02-04 18:05:05,975 - kedro.runner.sequential_runner - WARNING - There are 12 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],data_imputation,merge_to_grid,add_sag_features_by_hour([data_primary,parameters]) -> [data_sag_features_by_hour],create_features,add_across_features_by_hour([data_sag_features_by_hour,parameters]) -> [data_general_features],group_by_shift([data_general_features,parameters]) -> [data_aggregated],add_sag_features_by_shift([data_aggregated,parameters]) -> [data_sag_features_by_shift],add_across_features_by_shift([data_sag_features_by_shift,parameters]) -> [data_features_by_shift],create_target_counts([data_features_by_shift,data_sag_features_by_hour,parameters,td]) -> [data_aggregated_counts],create_target_lags([data_aggregated_counts,parameters,td]) -> [data_all_features,data_all_features_csv]"
2021-02-04 18:17:11,085 - root - INFO - ** Kedro project optimus
2021-02-04 18:17:38,864 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:17:38,885 - kedro.pipeline.node - INFO - Running node: create_tag_dict([tag_dict_master]) -> [td]
2021-02-04 18:17:38,898 - kedro.io.data_catalog - INFO - Saving data to `td` (PickleDataSet)...
2021-02-04 18:17:38,926 - kedro.runner.sequential_runner - INFO - Completed 1 out of 18 tasks
2021-02-04 18:17:38,927 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 18:17:39,027 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:17:39,044 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 18:17:39,044 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 18:17:39,082 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 18:17:39,097 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 18:17:39,110 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 18:17:39,123 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 18:17:39,136 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 18:17:39,148 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 18:17:39,161 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 18:17:39,173 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 18:17:39,174 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 18:17:39,176 - kedro.runner.sequential_runner - INFO - Completed 2 out of 18 tasks
2021-02-04 18:17:39,176 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 18:18:34,731 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 18:18:34,741 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:18:34,759 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 18:18:34,760 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan]
2021-02-04 18:18:36,361 - kedro.io.data_catalog - INFO - Saving data to `data_corrected` (PickleDataSet)...
2021-02-04 18:18:44,827 - kedro.io.data_catalog - INFO - Saving data to `data_curation_stats_nan` (CSVDataSet)...
2021-02-04 18:18:44,900 - kedro.runner.sequential_runner - INFO - Completed 3 out of 18 tasks
2021-02-04 18:18:44,901 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 18:18:44,902 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:18:59,294 - kedro.pipeline.node - INFO - Running node: create_time_grid: create_time_grid([data_corrected,params:create_primary]) -> [time_grid]
2021-02-04 18:18:59,319 - kedro.io.data_catalog - INFO - Saving data to `time_grid` (MemoryDataSet)...
2021-02-04 18:18:59,327 - kedro.runner.sequential_runner - INFO - Completed 4 out of 18 tasks
2021-02-04 18:18:59,328 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:19:13,085 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected]) -> [data_norm]
2021-02-04 18:19:15,242 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 18:19:15,521 - kedro.runner.sequential_runner - INFO - Completed 5 out of 18 tasks
2021-02-04 18:19:15,522 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-04 18:19:15,805 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-04 18:20:50,141 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-04 18:20:50,698 - kedro.runner.sequential_runner - INFO - Completed 6 out of 18 tasks
2021-02-04 18:20:50,708 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 18:20:50,715 - kedro.io.data_catalog - INFO - Loading data from `time_grid` (MemoryDataSet)...
2021-02-04 18:20:50,719 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:21:25,760 - kedro.pipeline.node - INFO - Running node: merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]
2021-02-04 18:23:45,833 - kedro.pipeline.node - ERROR - Node `merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]` failed with error: 
Merging dataframe 1 led to a change in the number of rows from 9500 to 9503. Please check for duplicate timestamps.
2021-02-04 18:23:46,600 - kedro.runner.sequential_runner - WARNING - There are 12 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "merge_to_grid,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],data_imputation,add_sag_features_by_hour([data_primary,parameters]) -> [data_sag_features_by_hour],create_features,add_across_features_by_hour([data_sag_features_by_hour,parameters]) -> [data_general_features],group_by_shift([data_general_features,parameters]) -> [data_aggregated],add_sag_features_by_shift([data_aggregated,parameters]) -> [data_sag_features_by_shift],add_across_features_by_shift([data_sag_features_by_shift,parameters]) -> [data_features_by_shift],create_target_counts([data_features_by_shift,data_sag_features_by_hour,parameters,td]) -> [data_aggregated_counts],create_target_lags([data_aggregated_counts,parameters,td]) -> [data_all_features,data_all_features_csv]"
2021-02-04 18:44:26,904 - root - INFO - ** Kedro project optimus
2021-02-04 18:44:54,670 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:44:54,698 - kedro.pipeline.node - INFO - Running node: create_tag_dict([tag_dict_master]) -> [td]
2021-02-04 18:44:54,711 - kedro.io.data_catalog - INFO - Saving data to `td` (PickleDataSet)...
2021-02-04 18:44:54,738 - kedro.runner.sequential_runner - INFO - Completed 1 out of 18 tasks
2021-02-04 18:44:54,739 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 18:44:54,840 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:44:54,856 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 18:44:54,857 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 18:44:54,894 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 18:44:54,908 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 18:44:54,920 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 18:44:54,931 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 18:44:54,943 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 18:44:54,954 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 18:44:54,965 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 18:44:54,978 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 18:44:54,978 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 18:44:54,980 - kedro.runner.sequential_runner - INFO - Completed 2 out of 18 tasks
2021-02-04 18:44:54,980 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 18:45:50,532 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 18:45:50,542 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:45:50,559 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 18:45:50,560 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan]
2021-02-04 18:45:52,116 - kedro.io.data_catalog - INFO - Saving data to `data_corrected` (PickleDataSet)...
2021-02-04 18:46:00,676 - kedro.io.data_catalog - INFO - Saving data to `data_curation_stats_nan` (CSVDataSet)...
2021-02-04 18:46:00,719 - kedro.runner.sequential_runner - INFO - Completed 3 out of 18 tasks
2021-02-04 18:46:00,720 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:46:15,250 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected]) -> [data_norm]
2021-02-04 18:46:16,916 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 18:46:17,212 - kedro.runner.sequential_runner - INFO - Completed 4 out of 18 tasks
2021-02-04 18:46:17,213 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 18:46:17,214 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:46:25,278 - kedro.pipeline.node - INFO - Running node: create_time_grid: create_time_grid([data_corrected,params:create_primary]) -> [time_grid]
2021-02-04 18:46:25,385 - kedro.io.data_catalog - INFO - Saving data to `time_grid` (MemoryDataSet)...
2021-02-04 18:46:25,392 - kedro.runner.sequential_runner - INFO - Completed 5 out of 18 tasks
2021-02-04 18:46:25,393 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 18:46:25,394 - kedro.io.data_catalog - INFO - Loading data from `time_grid` (MemoryDataSet)...
2021-02-04 18:46:25,395 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:46:30,524 - kedro.pipeline.node - INFO - Running node: merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]
2021-02-04 18:46:30,525 - kedro.pipeline.node - ERROR - Node `merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]` failed with error: 
'tuple' object has no attribute 'drop_duplicates'
2021-02-04 18:47:36,629 - kedro.runner.sequential_runner - WARNING - There are 13 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],create_features,merge_to_grid,remove_outliers,add_sag_features_by_hour([data_primary,parameters]) -> [data_sag_features_by_hour],add_across_features_by_hour([data_sag_features_by_hour,parameters]) -> [data_general_features],group_by_shift([data_general_features,parameters]) -> [data_aggregated],add_sag_features_by_shift([data_aggregated,parameters]) -> [data_sag_features_by_shift],add_across_features_by_shift([data_sag_features_by_shift,parameters]) -> [data_features_by_shift],create_target_counts([data_features_by_shift,data_sag_features_by_hour,parameters,td]) -> [data_aggregated_counts],create_target_lags([data_aggregated_counts,parameters,td]) -> [data_all_features,data_all_features_csv]"
2021-02-04 18:58:11,645 - root - INFO - ** Kedro project optimus
2021-02-04 18:58:39,431 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 18:58:39,547 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:58:39,564 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 18:58:39,565 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 18:58:39,607 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 18:58:39,621 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 18:58:39,633 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 18:58:39,645 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 18:58:39,657 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 18:58:39,670 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 18:58:39,682 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 18:58:39,694 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 18:58:39,695 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 18:58:39,697 - kedro.runner.sequential_runner - INFO - Completed 1 out of 18 tasks
2021-02-04 18:58:39,697 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:58:39,714 - kedro.pipeline.node - INFO - Running node: create_tag_dict([tag_dict_master]) -> [td]
2021-02-04 18:58:39,723 - kedro.io.data_catalog - INFO - Saving data to `td` (PickleDataSet)...
2021-02-04 18:58:39,783 - kedro.runner.sequential_runner - INFO - Completed 2 out of 18 tasks
2021-02-04 18:58:39,784 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 18:59:34,860 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 18:59:34,870 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 18:59:34,887 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 18:59:34,888 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan]
2021-02-04 18:59:36,390 - kedro.io.data_catalog - INFO - Saving data to `data_corrected` (PickleDataSet)...
2021-02-04 18:59:45,715 - kedro.io.data_catalog - INFO - Saving data to `data_curation_stats_nan` (CSVDataSet)...
2021-02-04 18:59:45,748 - kedro.runner.sequential_runner - INFO - Completed 3 out of 18 tasks
2021-02-04 18:59:45,748 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 18:59:59,796 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected]) -> [data_norm]
2021-02-04 19:00:01,506 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 19:00:01,785 - kedro.runner.sequential_runner - INFO - Completed 4 out of 18 tasks
2021-02-04 19:00:01,786 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 19:00:01,786 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 19:00:13,807 - kedro.pipeline.node - INFO - Running node: create_time_grid: create_time_grid([data_corrected,params:create_primary]) -> [time_grid]
2021-02-04 19:00:13,824 - kedro.io.data_catalog - INFO - Saving data to `time_grid` (MemoryDataSet)...
2021-02-04 19:00:13,830 - kedro.runner.sequential_runner - INFO - Completed 5 out of 18 tasks
2021-02-04 19:00:13,831 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-04 19:00:14,086 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-04 19:01:55,402 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-04 19:01:55,758 - kedro.runner.sequential_runner - INFO - Completed 6 out of 18 tasks
2021-02-04 19:01:55,762 - kedro.io.data_catalog - INFO - Loading data from `params:create_primary` (MemoryDataSet)...
2021-02-04 19:01:55,768 - kedro.io.data_catalog - INFO - Loading data from `time_grid` (MemoryDataSet)...
2021-02-04 19:01:55,772 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 19:03:10,367 - kedro.pipeline.node - INFO - Running node: merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]
2021-02-04 19:11:25,220 - kedro.pipeline.node - ERROR - Node `merge_to_grid: merge_to_grid([data_corrected,params:create_primary,time_grid]) -> [data_primary]` failed with error: 

2021-02-04 19:11:25,267 - kedro.runner.sequential_runner - WARNING - There are 12 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "data_imputation,merge_to_grid,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],add_sag_features_by_hour([data_primary,parameters]) -> [data_sag_features_by_hour],create_features,add_across_features_by_hour([data_sag_features_by_hour,parameters]) -> [data_general_features],group_by_shift([data_general_features,parameters]) -> [data_aggregated],add_sag_features_by_shift([data_aggregated,parameters]) -> [data_sag_features_by_shift],add_across_features_by_shift([data_sag_features_by_shift,parameters]) -> [data_features_by_shift],create_target_counts([data_features_by_shift,data_sag_features_by_hour,parameters,td]) -> [data_aggregated_counts],create_target_lags([data_aggregated_counts,parameters,td]) -> [data_all_features,data_all_features_csv]"
2021-02-04 19:11:50,192 - root - INFO - ** Kedro project optimus
2021-02-04 19:13:08,134 - root - INFO - ** Kedro project optimus
2021-02-04 19:13:35,643 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 19:13:35,762 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 19:13:35,786 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 19:13:35,787 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 19:13:35,819 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 19:13:35,834 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 19:13:35,846 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 19:13:35,858 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 19:13:35,870 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 19:13:35,882 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 19:13:35,895 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 19:13:35,907 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 19:13:35,907 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 19:13:35,909 - kedro.runner.sequential_runner - INFO - Completed 1 out of 8 tasks
2021-02-04 19:13:35,909 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 19:14:40,803 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 19:14:40,813 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 19:14:40,831 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 19:14:40,832 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan]
2021-02-04 19:14:46,242 - kedro.io.data_catalog - INFO - Saving data to `data_corrected` (PickleDataSet)...
2021-02-04 19:14:55,495 - kedro.io.data_catalog - INFO - Saving data to `data_curation_stats_nan` (CSVDataSet)...
2021-02-04 19:14:55,599 - kedro.runner.sequential_runner - INFO - Completed 2 out of 8 tasks
2021-02-04 19:14:55,599 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 19:15:01,326 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected]) -> [data_norm]
2021-02-04 19:15:02,956 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 19:15:03,225 - kedro.runner.sequential_runner - INFO - Completed 3 out of 8 tasks
2021-02-04 19:15:03,226 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-04 19:15:03,486 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-04 19:19:58,434 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-04 19:19:58,930 - kedro.runner.sequential_runner - INFO - Completed 4 out of 8 tasks
2021-02-04 19:19:58,931 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-04 19:20:05,297 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-04 19:20:51,963 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-04 19:20:52,291 - kedro.runner.sequential_runner - INFO - Completed 5 out of 8 tasks
2021-02-04 19:20:52,292 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-04 19:20:52,295 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-04 19:20:55,180 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-04 19:22:19,676 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-04 19:22:19,986 - kedro.runner.sequential_runner - INFO - Completed 6 out of 8 tasks
2021-02-04 19:22:19,987 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-04 19:22:20,288 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-04 19:22:22,265 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 
Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'
2021-02-04 19:22:22,583 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-04 19:31:05,835 - root - INFO - ** Kedro project optimus
2021-02-04 19:31:34,287 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 19:31:34,395 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 19:31:34,414 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 19:31:34,414 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 19:31:34,450 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 19:31:34,464 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 19:31:34,477 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 19:31:34,489 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 19:31:34,502 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 19:31:34,515 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 19:31:34,532 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 19:31:34,545 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 19:31:34,545 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 19:31:34,547 - kedro.runner.sequential_runner - INFO - Completed 1 out of 8 tasks
2021-02-04 19:31:34,548 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 19:32:29,792 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 19:32:29,802 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 19:32:29,818 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 19:32:29,819 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected,data_curation_stats_nan]
2021-02-04 19:32:31,467 - kedro.io.data_catalog - INFO - Saving data to `data_corrected` (PickleDataSet)...
2021-02-04 19:32:40,064 - kedro.io.data_catalog - INFO - Saving data to `data_curation_stats_nan` (CSVDataSet)...
2021-02-04 19:32:40,097 - kedro.runner.sequential_runner - INFO - Completed 2 out of 8 tasks
2021-02-04 19:32:40,098 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 19:32:51,466 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected]) -> [data_norm]
2021-02-04 19:32:53,065 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 19:32:53,340 - kedro.runner.sequential_runner - INFO - Completed 3 out of 8 tasks
2021-02-04 19:32:53,341 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-04 19:32:53,608 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-04 19:35:20,556 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-04 19:35:21,104 - kedro.runner.sequential_runner - INFO - Completed 4 out of 8 tasks
2021-02-04 19:35:21,108 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-04 19:36:13,350 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-04 19:37:22,679 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-04 19:37:22,986 - kedro.runner.sequential_runner - INFO - Completed 5 out of 8 tasks
2021-02-04 19:37:22,989 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-04 19:37:23,023 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-04 19:37:25,705 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-04 19:39:10,302 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-04 19:39:10,589 - kedro.runner.sequential_runner - INFO - Completed 6 out of 8 tasks
2021-02-04 19:39:10,590 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-04 19:39:17,257 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-04 19:43:56,191 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 

2021-02-04 19:43:56,260 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-04 19:48:55,997 - root - INFO - ** Kedro project optimus
2021-02-04 19:49:11,273 - root - INFO - ** Kedro project optimus
2021-02-04 19:49:25,910 - root - INFO - ** Kedro project optimus
2021-02-04 19:49:53,322 - kedro.io.data_catalog - INFO - Loading data from `data_corrected` (PickleDataSet)...
2021-02-04 19:50:07,259 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected]) -> [data_norm]
2021-02-04 19:50:09,404 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 19:50:09,682 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-04 19:50:09,683 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-04 19:50:10,012 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-04 19:51:08,382 - kedro.pipeline.node - ERROR - Node `remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]` failed with error: 
[Errno 5] Input/output error
2021-02-04 19:51:08,387 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "create_features,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],remove_outliers"
2021-02-04 19:54:54,717 - root - INFO - ** Kedro project optimus
2021-02-04 19:55:21,943 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 19:55:22,052 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 19:55:22,068 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 19:55:22,069 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 19:55:22,105 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 19:55:22,122 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 19:55:22,135 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 19:55:22,148 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 19:55:22,161 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 19:55:22,173 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 19:55:22,185 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 19:55:22,197 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 19:55:22,198 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 19:55:22,200 - kedro.runner.sequential_runner - INFO - Completed 1 out of 8 tasks
2021-02-04 19:55:22,201 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 19:56:17,629 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 19:56:17,639 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 19:56:17,655 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 19:56:17,656 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]
2021-02-04 19:56:19,207 - kedro.io.data_catalog - INFO - Saving data to `data_corrected_csv` (CSVDataSet)...
2021-02-04 20:00:27,534 - kedro.io.data_catalog - INFO - Saving data to `data_curation_stats_nan` (CSVDataSet)...
2021-02-04 20:00:27,559 - kedro.runner.sequential_runner - INFO - Completed 2 out of 8 tasks
2021-02-04 20:00:27,560 - kedro.io.data_catalog - INFO - Loading data from `data_corrected_csv` (CSVDataSet)...
2021-02-04 20:01:18,062 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_corrected_csv]) -> [data_norm]
2021-02-04 20:01:19,894 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-04 20:01:20,175 - kedro.runner.sequential_runner - INFO - Completed 3 out of 8 tasks
2021-02-04 20:01:20,176 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-04 20:01:20,472 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-04 20:06:19,163 - kedro.pipeline.node - ERROR - Node `remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]` failed with error: 

2021-02-04 20:06:19,167 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "remove_outliers,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],create_features"
2021-02-04 20:06:30,520 - root - INFO - ** Kedro project optimus
2021-02-04 20:06:58,173 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-04 20:06:58,276 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 20:06:58,300 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-04 20:06:58,300 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-04 20:06:58,334 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-04 20:06:58,349 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-04 20:06:58,361 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-04 20:06:58,373 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-04 20:06:58,386 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-04 20:06:58,397 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-04 20:06:58,410 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-04 20:06:58,422 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-04 20:06:58,423 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-04 20:06:58,424 - kedro.runner.sequential_runner - INFO - Completed 1 out of 8 tasks
2021-02-04 20:06:58,425 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-04 20:07:54,003 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-04 20:07:54,013 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-04 20:07:54,030 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-04 20:07:54,030 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]
2021-02-04 20:12:58,854 - kedro.pipeline.node - ERROR - Node `replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]` failed with error: 
[Errno 5] Input/output error
2021-02-04 20:12:58,859 - kedro.runner.sequential_runner - WARNING - There are 7 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],create_features,replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]"
2021-02-09 18:43:34,371 - root - INFO - ** Kedro project optimus
2021-02-09 18:44:50,606 - root - INFO - ** Kedro project optimus
2021-02-09 18:45:19,279 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-09 18:45:19,683 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-09 18:45:19,714 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-09 18:45:19,715 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-09 18:45:19,752 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-09 18:45:19,766 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-09 18:45:19,779 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-09 18:45:19,791 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-09 18:45:19,803 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-09 18:45:19,815 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-09 18:45:19,827 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-09 18:45:19,839 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-09 18:45:19,840 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-09 18:45:19,841 - kedro.runner.sequential_runner - INFO - Completed 1 out of 8 tasks
2021-02-09 18:45:19,841 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 18:46:17,113 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 18:46:20,370 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 18:46:20,736 - kedro.runner.sequential_runner - INFO - Completed 2 out of 8 tasks
2021-02-09 18:46:20,737 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 18:47:15,677 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-09 18:47:15,693 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-09 18:47:15,711 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-09 18:47:15,712 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]
2021-02-09 18:47:37,109 - kedro.pipeline.node - ERROR - Node `replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]` failed with error: 

2021-02-09 18:47:37,121 - kedro.runner.sequential_runner - WARNING - There are 6 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan],create_features,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],remove_outliers"
2021-02-09 18:48:17,150 - root - INFO - ** Kedro project optimus
2021-02-09 18:48:45,828 - kedro.io.data_catalog - INFO - Loading data from `data_qa_table` (ExcelDataSet)...
2021-02-09 18:48:45,927 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-09 18:48:45,945 - kedro.io.data_catalog - INFO - Loading data from `params:curation` (MemoryDataSet)...
2021-02-09 18:48:45,946 - kedro.pipeline.node - INFO - Running node: go_or_no_go([data_qa_table,params:curation,tag_dict_master]) -> [go_or_nogo]
2021-02-09 18:48:45,983 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r2_feature, please check dictionary
2021-02-09 18:48:45,997 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r3_feature, please check dictionary
2021-02-09 18:48:46,010 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r4_feature, please check dictionary
2021-02-09 18:48:46,022 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r5_feature, please check dictionary
2021-02-09 18:48:46,034 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r6_feature, please check dictionary
2021-02-09 18:48:46,046 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r7_feature, please check dictionary
2021-02-09 18:48:46,059 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r9_feature, please check dictionary
2021-02-09 18:48:46,071 - project_clisham.pipelines.data_quality.qa_nodes - INFO - No tags were selected for feature: r10_feature, please check dictionary
2021-02-09 18:48:46,072 - kedro.io.data_catalog - INFO - Saving data to `go_or_nogo` (MemoryDataSet)...
2021-02-09 18:48:46,074 - kedro.runner.sequential_runner - INFO - Completed 1 out of 8 tasks
2021-02-09 18:48:46,075 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 18:49:37,627 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 18:49:39,519 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 18:49:39,814 - kedro.runner.sequential_runner - INFO - Completed 2 out of 8 tasks
2021-02-09 18:49:39,815 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 18:49:40,109 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 18:52:00,492 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 18:52:01,115 - kedro.runner.sequential_runner - INFO - Completed 3 out of 8 tasks
2021-02-09 18:52:01,116 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 18:53:32,164 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-09 18:53:32,844 - kedro.io.data_catalog - INFO - Loading data from `tag_dict_master` (CSVDataSet)...
2021-02-09 18:53:33,114 - kedro.io.data_catalog - INFO - Loading data from `go_or_nogo` (MemoryDataSet)...
2021-02-09 18:53:33,192 - kedro.pipeline.node - INFO - Running node: replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]
2021-02-09 18:54:04,626 - kedro.pipeline.node - ERROR - Node `replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan]` failed with error: 

2021-02-09 18:54:05,001 - kedro.runner.sequential_runner - WARNING - There are 5 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "data_imputation,replace_outliers_by_nan([data_det,go_or_nogo,parameters,tag_dict_master]) -> [data_corrected_csv,data_curation_stats_nan],add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp],create_features"
2021-02-09 18:58:14,898 - root - INFO - ** Kedro project optimus
2021-02-09 18:58:44,397 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 18:59:41,095 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 18:59:43,486 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 18:59:43,778 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-09 18:59:43,779 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 18:59:44,158 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 19:01:21,332 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 19:01:21,900 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-09 19:01:21,905 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-09 19:01:28,883 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-09 19:03:39,851 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-09 19:03:40,220 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-09 19:03:40,281 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-09 19:03:40,282 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-09 19:03:40,579 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-09 19:05:12,407 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-09 19:05:12,695 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-09 19:05:12,696 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-09 19:05:12,996 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-09 19:05:12,998 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-09 19:05:13,443 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-09 19:14:52,726 - root - INFO - ** Kedro project optimus
2021-02-09 19:15:23,809 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 19:16:20,257 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 19:16:22,633 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 19:16:23,050 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-09 19:16:23,051 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 19:16:23,359 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 19:18:13,363 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 19:18:13,987 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-09 19:18:13,990 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-09 19:18:24,044 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-09 19:19:59,846 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-09 19:20:00,291 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-09 19:20:00,292 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-09 19:20:00,326 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-09 19:20:05,734 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-09 19:21:38,747 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-09 19:21:39,093 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-09 19:21:39,094 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-09 19:21:39,477 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-09 19:24:38,196 - root - INFO - ** Kedro project optimus
2021-02-09 19:25:06,930 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 19:26:03,417 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 19:26:05,887 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 19:26:06,183 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-09 19:26:06,183 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 19:26:06,475 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 19:28:06,327 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 19:28:06,878 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-09 19:28:06,882 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-09 19:28:15,379 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-09 19:29:07,691 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-09 19:29:08,040 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-09 19:29:08,041 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-09 19:29:08,042 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-09 19:29:08,344 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-09 19:30:39,745 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-09 19:30:40,062 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-09 19:30:40,063 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-09 19:30:40,382 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-09 19:30:52,443 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 

2021-02-09 19:30:52,477 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-09 19:35:18,762 - root - INFO - ** Kedro project optimus
2021-02-09 19:35:47,561 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 19:36:44,034 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 19:36:46,560 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 19:36:46,857 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-09 19:36:46,858 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 19:36:47,243 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 19:38:55,402 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 19:38:55,921 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-09 19:38:55,925 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-09 19:39:04,244 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-09 19:40:03,330 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-09 19:40:03,631 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-09 19:40:03,632 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-09 19:40:03,632 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-09 19:40:03,936 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-09 19:41:34,551 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-09 19:41:34,836 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-09 19:41:34,836 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-09 19:41:35,120 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-09 19:41:35,128 - kedro.pipeline.node - ERROR - Node `group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]` failed with error: 
"None of ['Fecha'] are in the columns"
2021-02-09 19:41:35,336 - kedro.runner.sequential_runner - WARNING - There are 2 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "group_per_hour,add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-09 19:46:26,386 - root - INFO - ** Kedro project optimus
2021-02-09 19:46:55,236 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 19:48:05,231 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 19:48:07,119 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 19:48:07,394 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-09 19:48:07,394 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 19:48:07,668 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 19:51:07,989 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 19:51:08,272 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-09 19:51:08,272 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-09 19:51:23,077 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-09 19:52:12,160 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-09 19:52:12,445 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-09 19:52:12,446 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-09 19:52:12,447 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-09 19:52:12,814 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-09 19:53:44,457 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-09 19:53:44,768 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-09 19:53:44,769 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-09 19:53:45,053 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-09 19:53:53,089 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_grouped` (MemoryDataSet)...
2021-02-09 19:53:53,129 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-09 19:53:53,129 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-09 19:53:53,145 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_grouped` (MemoryDataSet)...
2021-02-09 19:53:53,194 - kedro.pipeline.node - INFO - Running node: add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]
2021-02-09 19:53:53,283 - kedro.pipeline.node - ERROR - Node `add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]` failed with error: 
'apertura_valv_descarga_l1_r2'
2021-02-09 19:53:53,484 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-09 20:00:38,623 - root - INFO - ** Kedro project optimus
2021-02-09 20:01:07,810 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 20:02:04,897 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 20:02:07,247 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 20:02:07,585 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-09 20:02:07,586 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 20:02:07,882 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 20:03:55,831 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 20:03:56,277 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-09 20:03:56,281 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-09 20:04:08,979 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-09 20:05:20,741 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-09 20:05:21,097 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-09 20:05:21,099 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-09 20:05:21,100 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-09 20:05:26,048 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-09 20:06:56,089 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-09 20:06:56,382 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-09 20:06:56,383 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-09 20:06:56,705 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-09 20:07:04,196 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_grouped` (MemoryDataSet)...
2021-02-09 20:07:04,236 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-09 20:07:04,237 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-09 20:07:04,248 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_grouped` (MemoryDataSet)...
2021-02-09 20:07:04,296 - kedro.pipeline.node - INFO - Running node: add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]
2021-02-09 20:07:05,055 - kedro.pipeline.node - ERROR - Node `add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]` failed with error: 
'promedio_apertura_valv_descarga_l1_r10'
2021-02-09 20:07:05,220 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]"
2021-02-09 20:11:21,950 - root - INFO - ** Kedro project optimus
2021-02-09 20:11:50,581 - kedro.io.data_catalog - INFO - Loading data from `data_det` (CSVDataSet)...
2021-02-09 20:12:46,398 - kedro.pipeline.node - INFO - Running node: parse_columns_esp: parse_column_names([data_det]) -> [data_norm]
2021-02-09 20:12:48,810 - kedro.io.data_catalog - INFO - Saving data to `data_norm` (MemoryDataSet)...
2021-02-09 20:12:49,111 - kedro.runner.sequential_runner - INFO - Completed 1 out of 6 tasks
2021-02-09 20:12:49,112 - kedro.io.data_catalog - INFO - Loading data from `data_norm` (MemoryDataSet)...
2021-02-09 20:12:49,517 - kedro.pipeline.node - INFO - Running node: remove_outliers: remove_outliers([data_norm]) -> [data_filtrada]
2021-02-09 20:14:39,600 - kedro.io.data_catalog - INFO - Saving data to `data_filtrada` (MemoryDataSet)...
2021-02-09 20:14:40,107 - kedro.runner.sequential_runner - INFO - Completed 2 out of 6 tasks
2021-02-09 20:14:40,265 - kedro.io.data_catalog - INFO - Loading data from `data_filtrada` (MemoryDataSet)...
2021-02-09 20:15:08,178 - kedro.pipeline.node - INFO - Running node: data_imputation: data_imputation([data_filtrada]) -> [data_general]
2021-02-09 20:16:17,921 - kedro.io.data_catalog - INFO - Saving data to `data_general` (MemoryDataSet)...
2021-02-09 20:16:18,201 - kedro.runner.sequential_runner - INFO - Completed 3 out of 6 tasks
2021-02-09 20:16:18,202 - kedro.io.data_catalog - INFO - Loading data from `params:general_tags_esp` (MemoryDataSet)...
2021-02-09 20:16:18,203 - kedro.io.data_catalog - INFO - Loading data from `data_general` (MemoryDataSet)...
2021-02-09 20:16:24,186 - kedro.pipeline.node - INFO - Running node: create_features: create_features([data_general,params:general_tags_esp]) -> [data_features_general]
2021-02-09 20:18:00,444 - kedro.io.data_catalog - INFO - Saving data to `data_features_general` (MemoryDataSet)...
2021-02-09 20:18:00,767 - kedro.runner.sequential_runner - INFO - Completed 4 out of 6 tasks
2021-02-09 20:18:00,768 - kedro.io.data_catalog - INFO - Loading data from `data_features_general` (MemoryDataSet)...
2021-02-09 20:18:01,068 - kedro.pipeline.node - INFO - Running node: group_per_hour: data_group_per_hour([data_features_general]) -> [data_all_features_grouped]
2021-02-09 20:18:08,854 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_grouped` (MemoryDataSet)...
2021-02-09 20:18:08,903 - kedro.runner.sequential_runner - INFO - Completed 5 out of 6 tasks
2021-02-09 20:18:08,904 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-02-09 20:18:08,916 - kedro.io.data_catalog - INFO - Loading data from `data_all_features_grouped` (MemoryDataSet)...
2021-02-09 20:18:08,964 - kedro.pipeline.node - INFO - Running node: add_on_off_features_by_hour([data_all_features_grouped,parameters]) -> [data_all_features_esp]
2021-02-09 20:18:10,944 - kedro.io.data_catalog - INFO - Saving data to `data_all_features_esp` (CSVDataSet)...
2021-02-09 20:19:03,210 - kedro.runner.sequential_runner - INFO - Completed 6 out of 6 tasks
2021-02-09 20:19:03,211 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
