{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial Notebook no how to implement and configure GE validation to run with pipeline\n",
    "##### In this tutorial, we would:\n",
    "    - overview of kedro-ge integration\n",
    "    - create and edit and expectation suite for a dataset\n",
    "    - add 2 types of expectations. (Table and column level)\n",
    "    - save expectations to our validation suite\n",
    "    - review the results in html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module helps identify anomalies and outliers in the dataset. It is based on kedro GE framework and has custom expectations that can be used.\n",
    "## How to get started?\n",
    "The following steps will help get started with setting up data validation.\n",
    "### Installing Kedro GE\n",
    "#### Step 1: Install kedro GE\n",
    "You can install kedro-great-expectations using pip. \n",
    "```commandline\n",
    "pip install optimus/packages/kedro_great_expectations-0.3.0-py3-none-any.whl\n",
    "```\n",
    "> .whl file for kedro_great_expectations is also available on [box](https://mckinsey.box.com/v/kedro-great-expectations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default Rules\n",
    "Please refer to this [link](https://docs.greatexpectations.io/en/v0.4.4/glossary.html) for all the available rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Using kedro GE in pipeline\n",
    "Modify your src/optimus_pkg/ins_data_assets/run.py to the following to enable validation on kedro run\n",
    "```python\n",
    "from kedro.context import KedroContext\n",
    "from kedro_great_expectations import GreatExpectationsMixin\n",
    " \n",
    "class ProjectContext(GreatExpectationsMixin, KedroContext):\n",
    "    # refer to sample config in optimus/pipeline/conf/base/kedro_ge.yml\n",
    "    ge_config_key = \"kedro_ge.yml\"   # optional, defaults to this value\n",
    "    ### ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Setting up and configuring great expectations\n",
    "When kedro GE is initiated, it generates a `kedro_ge.yml` configuration file  in the `conf/base` folder. This can be done by running the following command\n",
    "```commandline\n",
    "kedro ge init\n",
    "```\n",
    "This file can be configured to suit the project needs. The class path for custom expectations developed for OptimusAI is included in this file.\n",
    "For more information on how to configure, please refer to [GE documentation](https://one.quantumblack.com/docs/alchemy/kedro_great_expectations/03_user_guide/01_configuration.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Create a GE suite.\n",
    "The following commands will help create an empty GE suite for each dataset. Make sure you are in the pipeline folder before executing the commands.\n",
    " \n",
    "```commandline\n",
    "cd pipeline\n",
    "kedro ge generate <dataset_name> --empty\n",
    "kedro ge edit <dataset_name>\n",
    "``` \n",
    " This will open a jupyter notebook `dataset_name.ipynb` for editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 5: Build your Expectation Suite**\n",
    "OptimusAI has built some custom expectations that can be used in addition to those provided by GE. These can be found in the `great_expectations_utils.py` file. The custom expectation class and its methods are detailed in the `adtk_custom_expectation.py` file.\n",
    "Simply copy paste the desired method into the notebook. The below example implements Anomaly detection using quantiles.\n",
    "\n",
    "```python\n",
    "from optimus_pkg.data_validation.great_expectations_utils import *\n",
    "params = context.params\n",
    "\n",
    "# Custom Expectation - Quantile anomaly detection\n",
    "validate_column_quantile_anomaly(batch, params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter file for data validation module is located at `<my_project>/pipeline/conf/base/pipelines/validate/parameters.yml`\n",
    "\n",
    "```\n",
    "dataset_1:\n",
    "  column_list: [\"status_time\", \"outp_quantity\", \"inp_quantity\", \"cu_content\", \"inp_avg_hardness\"]\n",
    "\n",
    "  data_length:\n",
    "    min_value: 0\n",
    "    max_value: 26\n",
    "\n",
    "  schema:\n",
    "    \"cu_content\": \"float64\"\n",
    "    \"inp_avg_hardness\": \"float64\"\n",
    "    \"inp_quantity\": \"float64\"\n",
    "    \"outp_quantity\": \"float64\"\n",
    "    \"status_time\": \"object\"\n",
    "\n",
    "  time:\n",
    "    column: \"status_time\"\n",
    "    format: \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "  process_window: 8       #  amount of time to complete ops process\n",
    "\n",
    "  sensor_pair_1:\n",
    "    first_sensor: \"inp_quantity\"\n",
    "    second_sensor: \"outp_quantity\"\n",
    "\n",
    "  quantile_anomaly:\n",
    "    low: 0.01             # Quantile of historical data lower which a value is regarded as anomaly\n",
    "    high:  0.99           # Quantile of historical data above which a value is regarded as anomaly\n",
    "```\n",
    "Params are designated by dataset i.e. each data can have their own top level key to differentiate between config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Expectations\n",
    "Currently, OptimusAI supports two types of anomaly detection. \n",
    "- Rule based anomaly detection\n",
    "- Model based advanced anomaly detection\n",
    "\n",
    "All of them have been implemented using the Anomaly Detection ToolKit ([ADTK](https://adtk.readthedocs.io/en/stable/index.html)) package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule based anomaly detection\n",
    "The following methods detect anomalies using set rules to detect anomalies.\n",
    "1. Level Shift Anomaly Detection: `create_level_shift_expectation`\n",
    "This detects level shifts in the dataset by comparing values from two time windows.\n",
    "2. Quantile Anomaly Detection: `validate_column_quantile_anomaly`\n",
    "This detects anomalies based on quantiles of historical data\n",
    "3. Persist Anomaly Detection: `validate_column_persist_anomaly`\n",
    "This detects anomalies based on values in a preceding time period.\n",
    "\n",
    "#### Advanced Anomaly detection \n",
    "Sometimes, it is difficult to detect anomalies based on simple rules. Model based anomaly detection can help solve this issue. The following methods are currently available. \n",
    "1. Isolation Forest: `validate_multi_dimension_isolationforest_anomaly`\n",
    "This method identifies time points as anomalous based isolation forest technique. This is a tree based technique and is highly effective in high dimensional data. \n",
    "2. KMeans Clustering: `validate_multi_dimension_cluster_anomaly`\n",
    "This method identifies anomalies based on clustering historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "### 1. Can I add my own expectation?\n",
    "Yes, you can create your own expectation. \n",
    "1. Go to ./pipeline/src/optimus_pkg/data_validation/adtk_custom_expectation.py\n",
    "2. Add your function to the class `CustomADTKExpectations`.\n",
    "3. Include your function in the GE utils file, i.e., `great_expectations_utils.py`. \n",
    "4. Call this function when creating your GE suite through the jupyter notebook generated for your dataset.\n",
    "\n",
    "### 2. What are decorators? How is it used here?\n",
    "Decorators are callable objects that add new functionality to existing objects without modifying its structure. GE provides high-level decorators that help convert our custom functions into a fully-fledged expectation.\n",
    "We use `column_aggregate_expectation` decorator from class `MetaPandasDataset`, other options include . For more information on them, refer to the [GE documentation](https://docs.greatexpectations.io/en/latest/autoapi/great_expectations/dataset/index.html#great_expectations.dataset.MetaPandasDataset). \n",
    "\n",
    "### 3. How should I configure my expectation file?\n",
    "You can configure how validation works for your datasets by using the following config schema available [here](https://one.quantumblack.com/docs/alchemy/kedro_great_expectations/03_user_guide/01_configuration.html)\n",
    "\n",
    "### 4. Something is not right. How can I get in touch?\n",
    "Please raise an issue [here](https://git.mckinsey-solutions.com/opm/optimus/issues/new/choose). Alternatively, get in touch via slack [#optimus](https://mckinsey-client-cap.slack.com/archives/C9S1RM6SX)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a GE validation  notebook\n",
    "Use this notebook to recreate and modify your expectation suite:\n",
    "\n",
    "**Expectation Suite Name**: `dataset_name` <br>\n",
    "*for this tutorial we would use in_out_recent as our dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17 13:35:14,111 - root - INFO - ** Kedro project optimus_pkg\n",
      "2020-08-17 13:35:14,112 - root - INFO - Defined global variable `context` and `catalog`\n",
      "2020-08-17 13:35:14,117 - root - INFO - Registered line magic `run_viz`\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset and assign batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17T13:35:16-0500 - INFO - Great Expectations logging enabled at 20 level by JupyterUX module.\n",
      "2020-08-17 13:35:16,153 - great_expectations - INFO - Great Expectations logging enabled at 20 level by JupyterUX module.\n",
      "2020-08-17 13:35:16,286 - py.warnings - WARNING - /Users/Jeffery_Annor/anaconda3/envs/opt/lib/python3.7/site-packages/patsy/constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping\n",
      "\n",
      "2020-08-17 13:35:16,419 - py.warnings - WARNING - /Users/Jeffery_Annor/anaconda3/envs/opt/lib/python3.7/site-packages/jsonschema/validators.py:928: DeprecationWarning: The metaschema specified by $schema was not found. Using the latest draft to validate, but this will raise an error in the future.\n",
      "  cls = validator_for(schema)\n",
      "\n",
      "2020-08-17 13:35:16,461 - kedro.io.data_catalog - INFO - Loading data from `in_out_recent` (CSVDataSet)...\n",
      "2020-08-17 13:35:16,524 - py.warnings - WARNING - /Users/Jeffery_Annor/anaconda3/envs/opt/lib/python3.7/site-packages/great_expectations/data_asset/data_asset.py:82: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self._batch_parameters = batch_parameters\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_time</th>\n",
       "      <th>inp_quantity</th>\n",
       "      <th>cu_content</th>\n",
       "      <th>outp_quantity</th>\n",
       "      <th>inp_avg_hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-27 03:59:58</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.079816</td>\n",
       "      <td>159</td>\n",
       "      <td>0.478026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27 04:14:59</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.079816</td>\n",
       "      <td>238</td>\n",
       "      <td>0.503276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-27 04:29:56</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.079816</td>\n",
       "      <td>246</td>\n",
       "      <td>0.506612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-27 04:45:04</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.079816</td>\n",
       "      <td>251</td>\n",
       "      <td>0.518337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-27 05:00:00</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.079683</td>\n",
       "      <td>242</td>\n",
       "      <td>0.489977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           status_time  inp_quantity  cu_content  outp_quantity  \\\n",
       "0  2020-07-27 03:59:58         147.0    0.079816            159   \n",
       "1  2020-07-27 04:14:59         230.0    0.079816            238   \n",
       "2  2020-07-27 04:29:56         251.0    0.079816            246   \n",
       "3  2020-07-27 04:45:04         250.0    0.079816            251   \n",
       "4  2020-07-27 05:00:00         240.0    0.079683            242   \n",
       "\n",
       "   inp_avg_hardness  \n",
       "0          0.478026  \n",
       "1          0.503276  \n",
       "2          0.506612  \n",
       "3          0.518337  \n",
       "4          0.489977  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import great_expectations.jupyter_ux\n",
    "from great_expectations.data_context.types.resource_identifiers import (\n",
    "    ValidationResultIdentifier,\n",
    ")\n",
    "from kedro_great_expectations.config import KedroGEConfig\n",
    "from kedro_great_expectations import ge_context as ge\n",
    "\n",
    "kedro_ge_config = KedroGEConfig.for_interactive_mode(context)\n",
    "\n",
    "data_context = ge.get_ge_context()\n",
    "\n",
    "expectation_suite_name = \"in_out_recent\"\n",
    "dataset_name = \"in_out_recent\"\n",
    "suite = data_context.get_expectation_suite(expectation_suite_name)\n",
    "suite.expectations = []\n",
    "\n",
    "# Use kedro to load the dataset:\n",
    "batch_kwargs = ge.get_batch_kwargs(\n",
    "    data=catalog.load(dataset_name), ds_name=dataset_name, ge_context=data_context\n",
    ")\n",
    "batch = data_context.get_batch(batch_kwargs, suite.expectation_suite_name)\n",
    "batch.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear all expectations\n",
    "\n",
    "If this is the first time you're editing this expectation suite and you've autogenerated the expectations, you may wish to clear all and add the expectations selectively.\n",
    "\n",
    "In that case, run the code cell below and execute the cells containing the expectations you wish to keep before saving the suite. You can either delete the cells of those you don't wish to keep, but they will be automatically removed the next time you run `kedro ge edit in_out_recent` anyway.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch._expectation_suite.expectations = []\n",
    "from optimus_pkg.core.data_validation.great_expectations_utils import *\n",
    "params = context.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Expectation(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate if sensors are part of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sensor_exist_expectation(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate if tags are part of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_length_expectation(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Expectation(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate a dataset has no null values in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_not_null_expectations_from_tagdict(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the schema of a dataframe  with predefined key-pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_schema_expectation(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the timestamp column of the dataframe and ensure it conforms to the format provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_time_format_expectation(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the value range of a dataset based on expected values defined in the TagDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17 13:35:32,157 - kedro.io.data_catalog - INFO - Loading data from `td` (TagDictCSVLocalDataSet)...\n"
     ]
    }
   ],
   "source": [
    "# load tag dictionary\n",
    "td = catalog.load('td')\n",
    "create_range_expectations_from_tagdict(batch, td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the sensor pairs to ensure if they have the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sensor_pair_equals_expectation(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate sensor values are not violating flatline rules i.e. no data change with in a process period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_flatline_expectation(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate sensor values are not violating quantile anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_column_quantile_anomaly(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate sensor values are not violating level shift anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17 13:35:37,340 - numexpr.utils - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2020-08-17 13:35:37,341 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "create_level_shift_expectation(batch, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_column_persist_anomaly(batch, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17 13:35:38,654 - py.warnings - WARNING - /Users/Jeffery_Annor/anaconda3/envs/opt/lib/python3.7/site-packages/great_expectations/data_asset/data_asset.py:82: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self._batch_parameters = batch_parameters\n",
      "\n",
      "2020-08-17 13:35:38,667 - py.warnings - WARNING - /Users/Jeffery_Annor/anaconda3/envs/opt/lib/python3.7/site-packages/great_expectations/data_asset/data_asset.py:82: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self._batch_parameters = batch_parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate_multi_dimension_cluster_anomaly(batch, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Your Expectations\n",
    "\n",
    "Let's save the expectation suite as a JSON file in the `great_expectations/expectations` directory of your project.\n",
    "If you decide not to save some expectations that you created, use the [remove_expectaton method](https://docs.greatexpectations.io/en/latest/module_docs/data_asset_module.html?highlight=remove_expectation&utm_source=notebook&utm_medium=edit_expectations#great_expectations.data_asset.data_asset.DataAsset.remove_expectation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17T13:35:41-0500 - INFO - \t37 expectation(s) included in expectation_suite. result_format settings filtered.\n",
      "2020-08-17 13:35:41,525 - great_expectations.data_asset.data_asset - INFO - \t37 expectation(s) included in expectation_suite. result_format settings filtered.\n",
      "2020-08-17 13:35:41,538 - py.warnings - WARNING - /Users/Jeffery_Annor/anaconda3/envs/opt/lib/python3.7/site-packages/jsonschema/validators.py:928: DeprecationWarning: The metaschema specified by $schema was not found. Using the latest draft to validate, but this will raise an error in the future.\n",
      "  cls = validator_for(schema)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch.save_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review your Expectations (optional)\n",
    "\n",
    "Let's now run the validation operators against your expectation suite and rebuild your Data Docs, which helps you communicate about your data with both machines and humans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17T13:35:43-0500 - INFO - \t37 expectation(s) included in expectation_suite.\n",
      "2020-08-17 13:35:43,861 - great_expectations.data_asset.data_asset - INFO - \t37 expectation(s) included in expectation_suite.\n",
      "2020-08-17 13:35:44,011 - py.warnings - WARNING - /Users/Jeffery_Annor/anaconda3/envs/opt/lib/python3.7/site-packages/great_expectations/core/__init__.py:113: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if not isinstance(data, list) and np.isnan(data):\n",
      "\n",
      "2020-08-17T13:35:45-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T123040.481823Z-kedro-ge-edit', '0df4b063f9a0d43d3070ff458c3f8ed6') - skipping\n",
      "2020-08-17 13:35:45,118 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T123040.481823Z-kedro-ge-edit', '0df4b063f9a0d43d3070ff458c3f8ed6') - skipping\n",
      "2020-08-17T13:35:45-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T120424.398851Z-kedro-ge-edit', '0c71db97883f0e7a985c475fc6425960') - skipping\n",
      "2020-08-17 13:35:45,122 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T120424.398851Z-kedro-ge-edit', '0c71db97883f0e7a985c475fc6425960') - skipping\n",
      "2020-08-17T13:35:45-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T115844.812554Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n",
      "2020-08-17 13:35:45,127 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T115844.812554Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n",
      "2020-08-17T13:35:45-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T115740.472650Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n",
      "2020-08-17 13:35:45,131 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T115740.472650Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n",
      "2020-08-17T13:35:55-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T123040.481823Z-kedro-ge-edit', '0df4b063f9a0d43d3070ff458c3f8ed6') - skipping\n",
      "2020-08-17 13:35:55,848 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T123040.481823Z-kedro-ge-edit', '0df4b063f9a0d43d3070ff458c3f8ed6') - skipping\n",
      "2020-08-17T13:35:55-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T120424.398851Z-kedro-ge-edit', '0c71db97883f0e7a985c475fc6425960') - skipping\n",
      "2020-08-17 13:35:55,852 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T120424.398851Z-kedro-ge-edit', '0c71db97883f0e7a985c475fc6425960') - skipping\n",
      "2020-08-17T13:35:55-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T115844.812554Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n",
      "2020-08-17 13:35:55,856 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T115844.812554Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n",
      "2020-08-17T13:35:55-0500 - WARNING - Validation result not found: ('in_out_recent', '20200624T115740.472650Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n",
      "2020-08-17 13:35:55,860 - great_expectations.render.renderer.site_builder - WARNING - Validation result not found: ('in_out_recent', '20200624T115740.472650Z-kedro-ge-edit', '687d65aa22d5c70a4d18b5653759deec') - skipping\n"
     ]
    }
   ],
   "source": [
    "run_id = datetime.utcnow().strftime(\"%Y%m%dT%H%M%S.%fZ-kedro-ge-edit\")\n",
    "\n",
    "results = data_context.run_validation_operator(\"action_list_operator\", assets_to_validate=[batch], run_id=run_id)\n",
    "expectation_suite_identifier = list(results[\"details\"].keys())[0]\n",
    "validation_result_identifier = ValidationResultIdentifier(\n",
    "    expectation_suite_identifier=expectation_suite_identifier,\n",
    "    batch_identifier=batch.batch_kwargs.to_id(),\n",
    "    run_id=run_id\n",
    ")\n",
    "data_context.build_data_docs()\n",
    "data_context.open_data_docs(validation_result_identifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus_pkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
